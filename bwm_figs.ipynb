{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f01519",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0653ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from one.api import ONE\n",
    "from iblatlas.atlas import AllenAtlas\n",
    "from iblatlas.regions import BrainRegions\n",
    "from ibllib.atlas.plots import plot_swanson_vector\n",
    "#from brainwidemap.manifold.state_space_bwm import (plot_traj_and_dist,\n",
    "#                                                   plot_all)\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import to_hex\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import dataframe_image as dfi\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#sns.set(font_scale=1.5)\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "ba = AllenAtlas()\n",
    "br = BrainRegions()\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org',\n",
    "          password='international', silent=True)\n",
    "          \n",
    "# get pooled results here\n",
    "meta_pth = Path(one.cache_dir, 'meta')\n",
    "meta_pth.mkdir(parents=True, exist_ok=True)          \n",
    "\n",
    "pth_res = Path(one.cache_dir, 'manifold', 'res') \n",
    "pth_res.mkdir(parents=True, exist_ok=True)\n",
    "pth_avg = Path(one.cache_dir, 'manifold', 'avgs') \n",
    "pth_avg.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "sigl = 0.05\n",
    "\n",
    "variables = ['duringstim', 'duringchoice', 'duringfback', 'intertrial']\n",
    "\n",
    "meta_splits = { # 0:correct trials; 1: incorrect trials\n",
    "    'duringstim_all_0': ['block_duringstim_r_choice_r_f1', 'block_duringstim_l_choice_l_f1',\n",
    "                         'durings_srcrbl_slclbl', 'durings_srcrbr_slclbr',\n",
    "                         'durings_srcrbl_slclbr','durings_slclbl_srcrbr'],\n",
    "    'duringstim_subset': ['durings_srcrbr_slclbr', 'durings_srcrbl_slclbl',\n",
    "                         ],\n",
    "    'duringstim_all': ['block_duringstim_r_choice_r_f1', 'block_duringstim_l_choice_l_f1',\n",
    "                         'durings_srcrbl_slclbl', 'durings_srcrbr_slclbr',\n",
    "                         'durings_srcrbl_slclbr','durings_slclbl_srcrbr',\n",
    "                         'block_duringstim_r_choice_l_f2', 'block_duringstim_l_choice_r_f2', \n",
    "                         'durings_slcrbl_srclbl','durings_slcrbr_srclbr',\n",
    "                         'durings_slcrbr_srclbl', 'durings_slcrbl_srclbr'],\n",
    "    'duringstim_all_1': ['block_duringstim_r_choice_l_f2', 'block_duringstim_l_choice_r_f2', \n",
    "                         'durings_slcrbl_srclbl','durings_slcrbr_srclbr',\n",
    "                         'durings_slcrbr_srclbl', 'durings_slcrbl_srclbr'],\n",
    "\n",
    "    #'duringstim_old': ['block_stim_l_all', 'block_stim_r_all', \n",
    "    #               'stim_block_l', 'stim_block_r',\n",
    "    #               'block_concordant', 'block_discordant', 'concordant'],\n",
    "    'duringstim': ['block_duringstim_r_choice_r_f1', 'block_duringstim_l_choice_l_f1',\n",
    "                   'block_duringstim_l_choice_r_f2', 'block_duringstim_r_choice_l_f2'],\n",
    "    'act_duringstim': ['act_block_duringstim_r_choice_r_f1', 'act_block_duringstim_l_choice_l_f1',\n",
    "                   'act_block_duringstim_l_choice_r_f2', 'act_block_duringstim_r_choice_l_f2'],\n",
    "    'duringchoice': ['block_stim_r_duringchoice_r_f1', 'block_stim_l_duringchoice_l_f1',\n",
    "                     'block_stim_l_duringchoice_r_f2', 'block_stim_r_duringchoice_l_f2'],\n",
    "    'act_duringchoice': ['act_block_stim_r_duringchoice_r_f1', 'act_block_stim_l_duringchoice_l_f1',\n",
    "                     'act_block_stim_l_duringchoice_r_f2', 'act_block_stim_r_duringchoice_l_f2'],\n",
    "    #'duringchoice_old': ['block_choice_l', 'block_choice_r',\n",
    "    #                 'choice_block_l', 'choice_block_r',\n",
    "    #                 'block_concordant_duringchoice', 'block_discordant_duringchoice',\n",
    "    #                'concordant_duringchoice'],\n",
    "    'duringchoice_all_0': ['block_stim_r_duringchoice_r_f1', 'block_stim_l_duringchoice_l_f1',\n",
    "                         'duringc_srcrbl_slclbl', 'duringc_srcrbr_slclbr',\n",
    "                         'duringc_srcrbl_slclbr','duringc_slclbl_srcrbr'],\n",
    "    'duringchoice_subset': ['duringc_srcrbl_slclbl', 'duringc_srcrbr_slclbr',\n",
    "                         ],\n",
    "    'duringchoice_all': ['block_stim_r_duringchoice_r_f1', 'block_stim_l_duringchoice_l_f1',\n",
    "                         'duringc_srcrbl_slclbl', 'duringc_srcrbr_slclbr',\n",
    "                         'duringc_srcrbl_slclbr','duringc_slclbl_srcrbr',\n",
    "                         'block_stim_r_duringchoice_l_f2', 'block_stim_l_duringchoice_r_f2', \n",
    "                         'duringc_slcrbl_srclbl','duringc_slcrbr_srclbr',\n",
    "                         'duringc_slcrbr_srclbl', 'duringc_slcrbl_srclbr'],\n",
    "    'duringchoice_all_1': ['block_stim_r_duringchoice_l_f2', 'block_stim_l_duringchoice_r_f2', \n",
    "                         'duringc_slcrbl_srclbl','duringc_slcrbr_srclbr',\n",
    "                         'duringc_slcrbr_srclbl', 'duringc_slcrbl_srclbr'],\n",
    "    'intertrial': ['block_stim_r_choice_r_f1', 'block_stim_l_choice_l_f1',\n",
    "                  'block_stim_l_choice_r_f2', 'block_stim_r_choice_l_f2'],\n",
    "    'act_intertrial': ['act_block_stim_r_choice_r_f1', 'act_block_stim_l_choice_l_f1',\n",
    "                  'act_block_stim_l_choice_r_f2', 'act_block_stim_r_choice_l_f2'],\n",
    "    'intertrial_all_0': ['block_stim_r_choice_r_f1', 'block_stim_l_choice_l_f1',\n",
    "                         'srcrbl_slclbl', 'srcrbr_slclbr',\n",
    "                         'srcrbl_slclbr','slclbl_srcrbr'],\n",
    "    'intertrial_all': ['block_stim_r_choice_r_f1', 'block_stim_l_choice_l_f1',\n",
    "                         'srcrbl_slclbl', 'srcrbr_slclbr',\n",
    "                         'srcrbl_slclbr','slclbl_srcrbr',\n",
    "                         'block_stim_r_choice_l_f2', 'block_stim_l_choice_r_f2', \n",
    "                         'slcrbl_srclbl','slcrbr_srclbr',\n",
    "                         'slcrbr_srclbl', 'slcrbl_srclbr'],\n",
    "    'intertrial_all_1': ['block_stim_r_choice_l_f2', 'block_stim_l_choice_r_f2', \n",
    "                         'slcrbl_srclbl','slcrbr_srclbr',\n",
    "                         'slcrbr_srclbl', 'slcrbl_srclbr'],\n",
    "    'sc_duringstim': ['stim', 'choice_duringstim'], # sc splits: always stim first, choice last\n",
    "    'sc_duringchoice': ['stim_duringchoice', 'choice'],\n",
    "    'sc_duringstim1': ['stim_choice_l', 'stim_choice_r', \n",
    "                       'choice_duringstim_l', 'choice_duringstim_r'],\n",
    "    'sc_duringchoice1': ['stim_duringchoice_l', 'stim_duringchoice_r', \n",
    "                         'choice_stim_l', 'choice_stim_r'],\n",
    "    'sc_duringfback': ['stim_duringfback', 'choice_duringfback'],\n",
    "    'sc_intertrial': ['stim_intertrial', 'choice_intertrial']\n",
    "}\n",
    "\n",
    "\n",
    "# [pre_time, post_time]\n",
    "pre_post = {}\n",
    "for meta_split in meta_splits:\n",
    "    if 'durings' in meta_split:\n",
    "        pre_post[meta_split] = [0,0.15]\n",
    "    elif 'duringc' in meta_split:\n",
    "        pre_post[meta_split] = [-0.2,0.35]\n",
    "    elif 'intertrial' in meta_split:\n",
    "        pre_post[meta_split] = [0.4,-0.1]\n",
    "for split in ['block_duringstim_l_choice_l_f1', 'block_duringstim_r_choice_r_f1',\n",
    "              'block_stim_l_duringchoice_l_f1', 'block_stim_r_duringchoice_r_f1',\n",
    "              'block_stim_l_choice_l_f1', 'block_stim_r_choice_r_f1',\n",
    "              'block_duringstim_l_choice_r_f2', 'block_duringstim_r_choice_l_f2',\n",
    "              'block_stim_l_duringchoice_r_f2', 'block_stim_r_duringchoice_l_f2',\n",
    "              'block_stim_l_choice_r_f2', 'block_stim_r_choice_l_f2'\n",
    "             ]:\n",
    "    if 'durings' in split:\n",
    "        pre_post[split] = [0,0.15]\n",
    "    elif 'duringc' in split:\n",
    "        pre_post[split] = [-0.2,0.35]\n",
    "    else:\n",
    "        pre_post[split] = [0.4,-0.1]\n",
    "for split in ['block_stim_l_duringchoice_l_f1_long', \n",
    "              'block_stim_r_duringchoice_r_f1_long']:\n",
    "    pre_post[split] = [-0.2,0.45]\n",
    "\n",
    "\n",
    "def swanson_to_beryl_hex(beryl_acronym,br):\n",
    "    beryl_id = br.id[br.acronym==beryl_acronym]\n",
    "    rgb = br.get(ids=beryl_id)['rgb'][0].astype(int)\n",
    "    return '#' + rgb_to_hex((rgb[0],rgb[1],rgb[2]))\n",
    "\n",
    "def beryl_to_cosmos(beryl_acronym,br):\n",
    "    beryl_id = br.id[br.acronym==beryl_acronym]\n",
    "    return br.get(ids=br.remap(beryl_id, source_map='Beryl', \n",
    "                  target_map='Cosmos'))['acronym'][0]\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '%02x%02x%02x' % rgb\n",
    "\n",
    "\n",
    "def get_name(brainregion):\n",
    "    regid = br.id[np.argwhere(br.acronym == brainregion)][0, 0]\n",
    "    return br.name[np.argwhere(br.id == regid)[0, 0]]\n",
    "\n",
    "\n",
    "def get_cmap_(meta_split):\n",
    "    '''\n",
    "    for each split, get a colormap defined by Yanliang,\n",
    "    updated by Chris\n",
    "    '''\n",
    "    dc = {}\n",
    "    if 'int_mov' in meta_split or 'move_shape' in meta_split:\n",
    "        base_colors = ['#ffffb3', '#ffed6f', \n",
    "                          '#feda7e', '#feb23f', '#d55607']\n",
    "        base_cmap = LinearSegmentedColormap.from_list(\"orange_yellow\", base_colors)\n",
    "        dc[meta_split] = base_cmap(np.linspace(0, 1, 256))\n",
    "        dc[meta_split][0] = [int(\"57\", 16)/255, int(\"C1\", 16)/255, int(\"EB\", 16)/255, 1.0]  # #57C1EB = blue\n",
    "        # dc[meta_split][-1] = [int(\"d5\", 16)/255, int(\"56\", 16)/255, int(\"07\", 16)/255, 1.0]  # #d55607 = red\n",
    "    elif 'stim_' in meta_split:\n",
    "        dc[meta_split] = [\"#EAF4B3\",\"#D5E1A0\", \"#A3C968\",\n",
    "                          \"#86AF40\", \"#517146\",\"#33492E\"]\n",
    "    elif 'choice_' in meta_split:\n",
    "        dc[meta_split] = [\"#F8E4AA\",\"#F9D766\",\"#E8AC22\",\n",
    "                          \"#DA4727\",\"#96371D\"]\n",
    "    elif 'sc' in meta_split:\n",
    "        # dc[meta_split] = [\"#57C1EB\", \"#C7F9CC\", \"#FAD1E6\", \"#F49AC2\", \"#D36C9B\"] # blue-pink\n",
    "        dc[meta_split] = ['#57C1EB', '#ffffb3', '#ffed6f', \n",
    "                          '#feda7e', '#feb23f']\n",
    "    else:\n",
    "        dc[meta_split] = [\"#D0CDE4\",\"#998DC3\",\"#6159A6\",\n",
    "                          \"#42328E\", \"#262054\"]\n",
    "\n",
    "\n",
    "    return LinearSegmentedColormap.from_list(\"mycmap\", dc[meta_split])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda13652",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_align = {\n",
    "    'intertrial': ['block_stim_r_choice_r_f1', 'block_stim_l_choice_l_f1', \n",
    "                   'block_stim_l_choice_r_f2', 'block_stim_r_choice_l_f2'\n",
    "                   ],\n",
    "    'intertrial0': ['block_only'],\n",
    "    'block_duringstim': ['block_duringstim_r_choice_r_f1', 'block_duringstim_l_choice_l_f1', \n",
    "                     'block_duringstim_l_choice_r_f2', 'block_duringstim_r_choice_l_f2'\n",
    "                     ],\n",
    "    'block_duringchoice': ['block_stim_r_duringchoice_r_f1', 'block_stim_l_duringchoice_l_f1', \n",
    "                            'block_stim_l_duringchoice_r_f2', 'block_stim_r_duringchoice_l_f2'\n",
    "                            ],\n",
    "    'intertrial1': ['block_stim_r_choice_r_f1', 'block_stim_l_choice_l_f1', \n",
    "                   ],\n",
    "    'block_duringstim1': ['block_duringstim_r_choice_r_f1', 'block_duringstim_l_choice_l_f1', \n",
    "                     ],\n",
    "    'block_duringchoice1': ['block_stim_r_duringchoice_r_f1', 'block_stim_l_duringchoice_l_f1', \n",
    "                            ],\n",
    "    'act_intertrial': ['act_block_stim_r_choice_r_f1', 'act_block_stim_l_choice_l_f1', \n",
    "                   'act_block_stim_l_choice_r_f2', 'act_block_stim_r_choice_l_f2'\n",
    "                   ],\n",
    "    'act_intertrial0': ['act_block_only'],\n",
    "    'act_block_duringstim': ['act_block_duringstim_r_choice_r_f1', 'act_block_duringstim_l_choice_l_f1', \n",
    "                     'act_block_duringstim_l_choice_r_f2', 'act_block_duringstim_r_choice_l_f2'\n",
    "                     ],\n",
    "    'act_block_duringchoice': ['act_block_stim_r_duringchoice_r_f1', 'act_block_stim_l_duringchoice_l_f1', \n",
    "                            'act_block_stim_l_duringchoice_r_f2', 'act_block_stim_r_duringchoice_l_f2'\n",
    "                            ],\n",
    "    'stim_duringstim0': ['stim_choice_r_block_r', 'stim_choice_l_block_l', \n",
    "             'stim_choice_r_block_l', 'stim_choice_l_block_r'],\n",
    "    'choice_duringchoice0': ['choice_stim_r_block_r', 'choice_stim_l_block_l', \n",
    "               'choice_stim_r_block_l', 'choice_stim_l_block_r'],\n",
    "    'stim_duringchoice0': ['stim_duringchoice_r_block_r', \n",
    "                          'stim_duringchoice_l_block_l', \n",
    "                          'stim_duringchoice_r_block_l', \n",
    "                          'stim_duringchoice_l_block_r'],\n",
    "    'choice_duringstim0': ['choice_duringstim_r_block_r', \n",
    "                          'choice_duringstim_l_block_l', \n",
    "                          'choice_duringstim_r_block_l', \n",
    "                          'choice_duringstim_l_block_r'],\n",
    "    'act_stim_duringstim0': ['stim_choice_r_block_r_act', 'stim_choice_l_block_l_act', \n",
    "             'stim_choice_r_block_l_act', 'stim_choice_l_block_r_act'],\n",
    "    'act_choice_duringchoice0': ['choice_stim_r_block_r_act', 'choice_stim_l_block_l_act', \n",
    "               'choice_stim_r_block_l_act', 'choice_stim_l_block_r_act'],\n",
    "    'act_stim_duringchoice0': ['stim_duringchoice_r_block_r_act', \n",
    "                          'stim_duringchoice_l_block_l_act', \n",
    "                          'stim_duringchoice_r_block_l_act', \n",
    "                          'stim_duringchoice_l_block_r_act'],\n",
    "    'act_choice_duringstim0': ['choice_duringstim_r_block_r_act', \n",
    "                          'choice_duringstim_l_block_l_act', \n",
    "                          'choice_duringstim_r_block_l_act', \n",
    "                          'choice_duringstim_l_block_r_act'],\n",
    "    'stim_duringstim': ['stim_choice_l', 'stim_choice_r'], \n",
    "    'choice_duringchoice': ['choice_stim_l', 'choice_stim_r'],\n",
    "    'choice_duringstim': ['choice_duringstim_l', 'choice_duringstim_r'],\n",
    "    'stim_duringchoice': ['stim_duringchoice_l', 'stim_duringchoice_r'],\n",
    "    'stim_duringstim1': ['stim_block_l', 'stim_block_r'],\n",
    "    'act_stim_duringstim1': ['stim_block_l_act', 'stim_block_r_act'],\n",
    "    # 'stim_duringstim1': ['stim_choice_r_block_r_short', 'stim_choice_l_block_l_short', \n",
    "    #                      'stim_choice_r_block_l_short', 'stim_choice_l_block_r_short'], \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64824023-8b65-4824-bc56-5a4fb3459c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_splits = {\n",
    "    'duringstim': ['block_duringstim_r_choice_r_f1', 'block_duringstim_l_choice_l_f1',\n",
    "                   'block_duringstim_l_choice_r_f2', 'block_duringstim_r_choice_l_f2'],    \n",
    "    'duringchoice': ['block_stim_r_duringchoice_r_f1', 'block_stim_l_duringchoice_l_f1',\n",
    "                     'block_stim_l_duringchoice_r_f2', 'block_stim_r_duringchoice_l_f2'],\n",
    "    'intertrial': ['block_stim_r_choice_r_f1', 'block_stim_l_choice_l_f1',\n",
    "                  'block_stim_l_choice_r_f2', 'block_stim_r_choice_l_f2'],\n",
    "}\n",
    "\n",
    "values = [1.0, 0.25, 0.125, 0.0625, 0.0]\n",
    "\n",
    "expanded_meta_splits={}\n",
    "for key, entries in meta_splits.items():\n",
    "    for value in values:\n",
    "        new_key = f\"{key}_{value}\"\n",
    "        expanded_meta_splits[new_key] = [f\"{entry}_{value}\" for entry in entries]\n",
    "\n",
    "pre_post = {}\n",
    "for meta_split in expanded_meta_splits:\n",
    "    if 'durings' in meta_split:\n",
    "        pre_post[meta_split] = [0,0.15]\n",
    "    elif 'duringc' in meta_split:\n",
    "        pre_post[meta_split] = [-0.2,0.35]\n",
    "    elif 'intertrial' in meta_split:\n",
    "        pre_post[meta_split] = [0.4,-0.1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192ce1b-7404-49c2-9644-6ccdbd7c39e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### plot sc region histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_threshold=0.6\n",
    "res = get_sc_table(times, ptype, alpha, sc_threshold=sc_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_threshold=0.6\n",
    "\n",
    "sc_duringstim = np.array(res['sc_duringstim'])\n",
    "sc_duringchoice = np.array(res['sc_duringchoice'])\n",
    "# sc_duringstim_mv = np.array(res['sc_duringstim_move_shape'].fillna(0))\n",
    "sc_duringchoice_mv = np.array(res['sc_duringchoice_move_shape'].fillna(0))\n",
    "\n",
    "# Fill NaNs only in the binary mv variables\n",
    "# sc_duringstim_mv = np.nan_to_num(sc_duringstim_mv, nan=0)\n",
    "sc_duringchoice_mv = np.nan_to_num(sc_duringchoice_mv, nan=0)\n",
    "\n",
    "sc_duringstim_mv = np.zeros_like(sc_duringstim, dtype=float)\n",
    "\n",
    "# Build DataFrames\n",
    "df_stim = pd.DataFrame({\n",
    "    \"sc_duringstim_mv\": sc_duringstim_mv,\n",
    "    \"sc_duringstim\": sc_duringstim\n",
    "})\n",
    "df_choice = pd.DataFrame({\n",
    "    \"sc_duringchoice_mv\": sc_duringchoice_mv,\n",
    "    \"sc_duringchoice\": sc_duringchoice\n",
    "})\n",
    "\n",
    "# Highlight subsets\n",
    "move_choice = df_choice[res['sc_duringchoice_int_mov']==1]\n",
    "stim_choice = df_choice[res['sc_duringchoice_int_mov']==0]\n",
    "int_choice = df_choice[res['sc_duringchoice_int_mov']==0.5]\n",
    "move_stim = df_stim[res['sc_duringstim_int_mov']==1]\n",
    "stim_stim = df_stim[res['sc_duringstim_int_mov']==0]\n",
    "int_stim = df_stim[res['sc_duringstim_int_mov']==0.5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4, 2), dpi=120, gridspec_kw={'width_ratios': [1, 2]}, sharey=True)\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"sc_duringchoice_mv\", y=\"sc_duringchoice\", data=int_choice,\n",
    "    color='#feda7e', jitter=0.25, ax=axes[1], size=3\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"sc_duringstim_mv\", y=\"sc_duringstim\", data=int_stim,\n",
    "    color='#feda7e', jitter=0.25, ax=axes[0], size=3\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"sc_duringstim_mv\", y=\"sc_duringstim\", data=move_stim,\n",
    "    color='#d55607', jitter=0.25, ax=axes[0], size=3\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"sc_duringchoice_mv\", y=\"sc_duringchoice\", data=move_choice,\n",
    "    color='#d55607', jitter=0.25, ax=axes[1], size=3\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"sc_duringstim_mv\", y=\"sc_duringstim\", data=stim_stim,\n",
    "    color='#57C1EB', jitter=0.25, ax=axes[0], size=3\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"sc_duringchoice_mv\", y=\"sc_duringchoice\", data=stim_choice,\n",
    "    color='#57C1EB', jitter=0.25, ax=axes[1], size=3\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"s_a\")\n",
    "axes[1].set_title(\"m_a\")\n",
    "\n",
    "for ax in axes:\n",
    "    # ax.axhline(sc_threshold, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_ylabel(r'$\\sum$ choice', fontsize=10)\n",
    "    ax.tick_params(labelsize=9)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_facecolor('none')\n",
    "\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_xticklabels([])\n",
    "\n",
    "axes[1].set_xlabel('mv-init ramp', fontsize=10)\n",
    "\n",
    "save_dir = '/Users/ariliu/Desktop/ibl-figures'\n",
    "fig.savefig(f'{save_dir}/sc_strip.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e45bb8-a897-4eb1-b0aa-9bc254ce67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_duringstim = np.array(res['sc_duringstim'])\n",
    "sc_duringchoice = np.array(res['sc_duringchoice'])\n",
    "sc_duringstim_mv = np.array(res['sc_duringstim_move_shape'].fillna(0))\n",
    "sc_duringchoice_mv = np.array(res['sc_duringchoice_move_shape'].fillna(0))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2, sharey=True, figsize=(4,2),dpi=120)\n",
    "\n",
    "axs[0].hist(sc_duringstim)\n",
    "axs[1].hist(sc_duringchoice)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r'$\\sum$ choice', fontsize=10)\n",
    "    ax.tick_params(labelsize=9)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "axs[0].set_title('during stim')\n",
    "axs[1].set_title('during choice')\n",
    "axs[0].set(ylabel='num regions')\n",
    "fig.tight_layout\n",
    "\n",
    "save_dir = '/Users/ariliu/Desktop/ibl-figures'\n",
    "fig.savefig(f'{save_dir}/sc_hist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277c5bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# decoding & projection of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752a421",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_proj_along_direction(reg, splits, colors, direction, pc=False,\n",
    "                              method='manifold', control=False):\n",
    "    \n",
    "    # load in decoding result to get choice/stim vector\n",
    "    pth = Path(one.cache_dir, 'decoding')\n",
    "    if method=='manifold':\n",
    "        pth = Path(one.cache_dir, 'manifold', 'traj_new')\n",
    "        r = np.load(Path(pth, f'traj_{reg}_{direction}.npy'), allow_pickle=True)\n",
    "        r0 = r[:,0,:]\n",
    "        r1 = r[:,1,:]\n",
    "\n",
    "        d = (r0-r1)**2\n",
    "        d1 = np.sum(d, axis=0)\n",
    "        maxd = max(d1)\n",
    "        maxidx = list(d1).index(maxd)\n",
    "        c_vec1 = d[:,maxidx]\n",
    "    else:\n",
    "        if method=='decoding':\n",
    "            x = np.load(Path(pth, f'{direction}_{reg}_original.npy'), allow_pickle=True).flatten()[0]\n",
    "        elif method=='decoding_pc':\n",
    "            x = np.load(Path(pth, f'{direction}_{reg}.npy'), allow_pickle=True).flatten()[0]\n",
    "        else:\n",
    "            print('what method to define proj direction?')\n",
    "            return\n",
    "\n",
    "        if control:\n",
    "            c_vec1 = x['avg_peth']\n",
    "        else:\n",
    "            max_acc = max(x['accuracy'])\n",
    "            idx = x['accuracy'].index(max_acc)\n",
    "            c_vec = x['readout'][idx]\n",
    "            c_vec1 = np.concatenate(c_vec)\n",
    "\n",
    "\n",
    "    labels = ['clbl', 'clbr', 'crbl', 'crbr']\n",
    "\n",
    "    i = 0\n",
    "    for split in splits:\n",
    "        # load in trajectory data\n",
    "        if 'pc' in method:\n",
    "            pth_r = Path(one.cache_dir, 'manifold', reg)\n",
    "        else:\n",
    "            pth_r = Path(one.cache_dir, 'manifold', 'traj_new')\n",
    "        r = np.load(Path(pth_r, f'traj_{reg}_{split}.npy'), allow_pickle=True)\n",
    "        #print(r.shape)\n",
    "        ntimes = r.shape[2]\n",
    "        r0 = r[:,0,:] #condition L trajectory\n",
    "        r1 = r[:,1,:] #condition R trajectory\n",
    "    \n",
    "        if pc:\n",
    "            # pca to transform data onto same space\n",
    "            a = np.concatenate([r0,r1], axis=1)\n",
    "            a = a.transpose() # shape of ntimes*2, ncells\n",
    "            a = np.append(a, c_vec, axis=0) # append c_vec together here for pca\n",
    "            \n",
    "            from sklearn.decomposition import PCA\n",
    "            pca = PCA(n_components=None)\n",
    "            a_pc = pca.fit_transform(a)\n",
    "            var = pca.explained_variance_ratio_\n",
    "            r0 = a_pc[:ntimes] #condition L trajectory in pc space\n",
    "            r1 = a_pc[ntimes:ntimes*2] #condition R trajectory in pc spacec\n",
    "            c_vec1 = a_pc[-1]\n",
    "        else:\n",
    "            r0 = r0.transpose()\n",
    "            r1 = r1.transpose()\n",
    "    \n",
    "        bl = np.dot(r0,c_vec1)\n",
    "        br = np.dot(r1,c_vec1)\n",
    "        xx = np.linspace(-pre_post[split][0], \n",
    "                         pre_post[split][1], \n",
    "                         len(bl))\n",
    "        plt.plot(xx, bl, c=colors[i])\n",
    "        plt.plot(xx, br, c=colors[i+1])\n",
    "        i+=2\n",
    "    \n",
    "    plt.legend(labels)\n",
    "    plt.title(reg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 'GRN'\n",
    "splits = ['block_duringstim_r_choice_r_f1', 'block_duringstim_l_choice_l_f1',\n",
    "          'block_stim_r_duringchoice_r_f1', 'block_stim_r_duringchoice_r_f1',\n",
    "          'block_stim_r_choice_r_f1', 'block_stim_l_choice_l_f1'\n",
    "         ]\n",
    "for split in splits:\n",
    "            #pth_r = Path(one.cache_dir, 'manifold', reg)\n",
    "            pth_r = Path(one.cache_dir, 'manifold', 'traj_new')\n",
    "            r = np.load(Path(pth_r, f'traj_{reg}_{split}.npy'), allow_pickle=True)\n",
    "            r0 = r[:,0,:]\n",
    "            r1 = r[:,1,:]\n",
    "            print(split, r0.shape, r1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa0def",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reg = 'GRN'\n",
    "splits = ['block_duringstim_l_choice_l_f1', 'block_duringstim_r_choice_r_f1',\n",
    "          'block_stim_l_duringchoice_l_f1', 'block_stim_r_duringchoice_r_f1',\n",
    "          #'block_stim_l_duringchoice_l_f1_long', 'block_stim_r_duringchoice_r_f1_long',\n",
    "          #'block_stim_l_choice_l_f1', 'block_stim_r_choice_r_f1'\n",
    "          #'block_duringstim_l_choice_r_f2', 'block_duringstim_r_choice_l_f2',\n",
    "          #'block_stim_l_duringchoice_r_f2', 'block_stim_r_duringchoice_l_f2',\n",
    "         ]\n",
    "colors = ['b', 'orange', 'c', 'r', 'b', 'orange', 'c', 'r',\n",
    "           'b', 'orange', 'c', 'r'\n",
    "          ]\n",
    "\n",
    "method = 'decoding'\n",
    "for direction in ['stim', 'choice']:\n",
    "    plot_proj_along_direction(reg, splits, colors, direction, pc=False, \n",
    "                              method=method)\n",
    "    plot_proj_along_direction(reg, splits, colors, direction, pc=True, \n",
    "                              method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd79fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_avg_proj_along_dir(regions, timespan, colors, direction='choice', pc=False,\n",
    "                            original=True, control=False, test=False):\n",
    "    pth = Path(one.cache_dir, 'decoding')\n",
    "    labels = ['clbl', 'crbl', 'clbr', 'crbr']\n",
    "    if timespan == 'duringchoice':\n",
    "        splits = ['block_stim_l_duringchoice_l_f1', 'block_stim_r_duringchoice_r_f1']\n",
    "    elif timespan == 'duringstim':\n",
    "        splits = ['block_duringstim_l_choice_l_f1', 'block_duringstim_r_choice_r_f1']\n",
    "    elif timespan == 'duringchoice1':\n",
    "        splits = ['block_stim_r_duringchoice_l_f2', 'block_stim_l_duringchoice_r_f2']\n",
    "    elif timespan == 'duringstim1':\n",
    "        splits = ['block_duringstim_r_choice_l_f2', 'block_duringstim_l_choice_r_f2']\n",
    "    elif timespan == 'intertrial':\n",
    "        splits = ['block_stim_l_choice_l_f1', 'block_stim_r_choice_r_f1']\n",
    "    elif timespan == 'intertrial1':\n",
    "        splits = ['block_stim_r_choice_l_f2', 'block_stim_l_choice_r_f2']\n",
    "    else:\n",
    "        print('timespan?')\n",
    "        return\n",
    "    \n",
    "    i = 0\n",
    "    for reg in regions:\n",
    "        # load choice decoding result to get choice direction\n",
    "        if original:\n",
    "            x = np.load(Path(pth, f'{direction}_{reg}_original.npy'), allow_pickle=True).flatten()[0]\n",
    "        else:\n",
    "            x = np.load(Path(pth, f'{direction}_{reg}.npy'), allow_pickle=True).flatten()[0]\n",
    "        max_acc = max(x['accuracy'])\n",
    "        idx = x['accuracy'].index(max_acc)\n",
    "        c_vec = x['readout'][idx]\n",
    "        c_vec = np.concatenate(c_vec)\n",
    "        if control==True:\n",
    "            c_vec = x['avg_peth']\n",
    "        if test:\n",
    "            c_vec = np.ones(len(x['avg_peth']))\n",
    "\n",
    "        print(reg)\n",
    "        \n",
    "        datal, datar = [], []\n",
    "        for split in splits:        \n",
    "            \n",
    "            # load manifold trajectories\n",
    "            pth_r = Path(one.cache_dir, 'manifold', reg)\n",
    "            r = np.load(Path(pth_r, f'traj_{reg}_{split}.npy'), allow_pickle=True)\n",
    "            r0 = r[:,0,:]\n",
    "            r1 = r[:,1,:]\n",
    "            print(r0.shape, np.sum(r0), np.sum(r1))\n",
    "            a = np.concatenate([r0,r1], axis=1)\n",
    "            a = a.transpose() # shape of ntimes*2, ncells\n",
    "            ntimes = r0.shape[1]\n",
    "    \n",
    "            if pc:\n",
    "                # pca to transform manifold data onto same space as choice decoding direction\n",
    "                ndim = min(len(c_vec), a.shape[0], a.shape[1])\n",
    "                if len(c_vec) > ndim: \n",
    "                    # use only the first ndim # of pc to define choice direction\n",
    "                    c_vec = c_vec[:ndim]\n",
    "                from sklearn.decomposition import PCA\n",
    "                pca = PCA(n_components=ndim)\n",
    "                a_pc = pca.fit_transform(a)\n",
    "                var = pca.explained_variance_ratio_\n",
    "                print('var_exp', sum(var))\n",
    "                r0 = a_pc[:ntimes] # shape of ntimes, npcs\n",
    "                r1 = a_pc[ntimes:]\n",
    "            \n",
    "            bl = np.dot(r0,c_vec)\n",
    "            br = np.dot(r1,c_vec)\n",
    "            #bl = np.mean(bl[48:])\n",
    "            #br = np.mean(br[48:])\n",
    "            bl = np.mean(bl)\n",
    "            br = np.mean(br)\n",
    "            datal.append(bl)\n",
    "            datar.append(br)\n",
    "            print('bl', bl, 'br', br)\n",
    "        \n",
    "        xx = [0,1,2,3]\n",
    "        plt.scatter(xx, np.concatenate([datal, datar]), c=colors[i], s=150)\n",
    "        i+=1\n",
    "    plt.xticks(xx, labels)\n",
    "    plt.legend(regions)\n",
    "    plt.title(timespan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272b2c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_slope_proj_along_dir(regions, timespan, colors, direction='choice', pc=False,\n",
    "                              original=True, control=False, test=False):\n",
    "    pth = Path(one.cache_dir, 'decoding')\n",
    "    labels = ['clbl', 'crbl', 'clbr', 'crbr']\n",
    "    if timespan == 'duringchoice':\n",
    "        splits = ['block_stim_l_duringchoice_l_f1', 'block_stim_r_duringchoice_r_f1']\n",
    "    elif timespan == 'duringstim':\n",
    "        splits = ['block_duringstim_l_choice_l_f1', 'block_duringstim_r_choice_r_f1']\n",
    "    elif timespan == 'duringchoice1':\n",
    "        splits = ['block_stim_r_duringchoice_l_f2', 'block_stim_l_duringchoice_r_f2']\n",
    "    elif timespan == 'duringstim1':\n",
    "        splits = ['block_duringstim_r_choice_l_f2', 'block_duringstim_l_choice_r_f2']\n",
    "    elif timespan == 'intertrial':\n",
    "        splits = ['block_stim_l_choice_l_f1', 'block_stim_r_choice_r_f1']\n",
    "    elif timespan == 'intertrial1':\n",
    "        splits = ['block_stim_r_choice_l_f2', 'block_stim_l_choice_r_f2']\n",
    "    else:\n",
    "        print('timespan?')\n",
    "        return\n",
    "    \n",
    "    i = 0\n",
    "    for reg in regions:\n",
    "        # load choice decoding result to get choice direction\n",
    "        if original:\n",
    "            x = np.load(Path(pth, f'{direction}_{reg}_original.npy'), allow_pickle=True).flatten()[0]\n",
    "        else:\n",
    "            x = np.load(Path(pth, f'{direction}_{reg}.npy'), allow_pickle=True).flatten()[0]\n",
    "        max_acc = max(x['accuracy'])\n",
    "        idx = x['accuracy'].index(max_acc)\n",
    "        c_vec = x['readout'][idx]\n",
    "        c_vec = np.concatenate(c_vec)\n",
    "        if control==True:\n",
    "            c_vec = x['avg_peth']\n",
    "        if test:\n",
    "            c_vec = np.ones(len(x['avg_peth']))\n",
    "\n",
    "        print(reg)\n",
    "        \n",
    "        datal, datar = [], []\n",
    "        for split in splits:        \n",
    "            \n",
    "            # load manifold trajectories\n",
    "            pth_r = Path(one.cache_dir, 'manifold', reg)\n",
    "            r = np.load(Path(pth_r, f'traj_{reg}_{split}.npy'), allow_pickle=True)\n",
    "            r0 = r[:,0,:]\n",
    "            r1 = r[:,1,:]\n",
    "            print(r0.shape, np.sum(r0), np.sum(r1))\n",
    "            \n",
    "            if pc:\n",
    "                # pca to transform manifold data onto same space as choice decoding direction\n",
    "                ndim = min(len(c_vec), a.shape[0], a.shape[1])\n",
    "                if len(c_vec) > ndim: \n",
    "                    # use only the first ndim # of pc to define choice direction\n",
    "                    c_vec = c_vec[:ndim]\n",
    "                from sklearn.decomposition import PCA\n",
    "                pca = PCA(n_components=ndim)\n",
    "                a_pc = pca.fit_transform(a)\n",
    "                var = pca.explained_variance_ratio_\n",
    "                print('var_exp', sum(var))\n",
    "                r0 = a_pc[:ntimes] # shape of ntimes, npcs\n",
    "                r1 = a_pc[ntimes:]\n",
    "\n",
    "            \n",
    "            bl = np.dot(r0,c_vec)\n",
    "            br = np.dot(r1,c_vec)\n",
    "            \n",
    "            if datatype == 'start':\n",
    "                datal.append(bl[0])\n",
    "                datar.append(br[0])\n",
    "            elif datatype == 'end':\n",
    "                datal.append(bl[len(bl)])\n",
    "                datar.append(br[len(br)])\n",
    "            elif datatype == 'slope':\n",
    "                bl_slope, br_slope = [], []\n",
    "                for j in range(len(bl)-1):\n",
    "                    bl_slope.append(bl[j+1]-bl[j])\n",
    "                    br_slope.append(br[j+1]-br[j])\n",
    "                bl = np.mean(bl_slope)\n",
    "                br = np.mean(br_slope)\n",
    "                datal.append(bl)\n",
    "                datar.append(br)\n",
    "            print('bl', bl, 'br', br)\n",
    "        \n",
    "        xx = [0,1,2,3]\n",
    "        plt.scatter(xx, np.concatenate([datal, datar]), c=colors[i], s=150)\n",
    "        i+=1\n",
    "    plt.xticks(xx, labels)\n",
    "    plt.legend(regions)\n",
    "    plt.title(timespan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dba731",
   "metadata": {},
   "source": [
    "why these values all symmetric?????\n",
    "look at traj along proj dir for incorrect trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66b87d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#regions = ['MRN', 'IRN', 'MOs']\n",
    "regions = ['GRN']#, 'MOp']#, 'PAG']\n",
    "timespan = 'duringstim'\n",
    "colors = ['b', 'orange', 'c']\n",
    "direction = 'choice'\n",
    "control=False\n",
    "test=False\n",
    "\n",
    "plot_avg_proj_along_dir(regions, timespan, colors, direction, control, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a889c2e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "regions = ['GRN', 'IRN', 'MOs', 'MRN', 'MOp', 'CENT3', 'SIM', \n",
    "           'IP', 'RSPagl', 'PL', 'AIv', 'PAG', 'CENT2', \n",
    "           'CP', 'ENTl', 'SUB', 'ZI', 'ANcr1', 'ACAd', 'APN']\n",
    "\n",
    "pth = Path(one.cache_dir, 'decoding')\n",
    "for region in regions:\n",
    "    x = np.load(Path(pth, f'choice_{region}.npy'), allow_pickle=True).flatten()[0]\n",
    "    print(region, 'mean_acc:', np.mean(x['accuracy']), 'p_val:', x['p_value'],\n",
    "         'var:', x['var_exp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f43035",
   "metadata": {},
   "source": [
    "# Manifold Distance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c8a45-3da7-4b1a-8cde-8d5778ed1b47",
   "metadata": {},
   "source": [
    "## line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96f284-2431-419d-b5aa-1906dfd127b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# show choice/stim diff in different block conditions\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "reg = 'MOs'\n",
    "splits = ['durings_srcrbl_slclbl', 'durings_srcrbr_slclbr'] #'srcrbl_slclbl', 'srcrbr_slclbr'\n",
    "if 'duringc' in splits[0]:\n",
    "    times = np.linspace(-0.15, 0, 72)\n",
    "    time='duringchoice'\n",
    "elif 'durings' in splits[0]:\n",
    "    times = np.linspace(0, 0.15, 72)\n",
    "    time='duringstim'\n",
    "else:\n",
    "    times = np.linspace(-0.4, -0.1, 144)\n",
    "    time='intertrial'\n",
    "\n",
    "fig = plt.figure(figsize=(4,3), dpi=150)\n",
    "\n",
    "for split in splits:\n",
    "    try:\n",
    "        r = np.load(Path(pth_res,f'd_with_controls_{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "    except BaseException:\n",
    "        print(\"error:\", split)\n",
    "        continue\n",
    "    if 'bl' in split:\n",
    "        r[0]=-1*r[0]\n",
    "        block='L'\n",
    "    else:\n",
    "        block='R'\n",
    "\n",
    "    plt.plot(times, r[0], label=f'block{block}')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(4))\n",
    "\n",
    "plt.savefig(f'/Users/ariliu/Desktop/{reg}_{time}_dist_trtl.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237f3ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OLD VERS - compare distance with controls\n",
    "reg = 'IRN'\n",
    "#splits = meta_splits['duringstim']\n",
    "splits = ['block_stim_r_duringchoice_r_f1'] #'act_block_stim_r_choice_r_f1'\n",
    "if 'duringchoice' in splits[0]:\n",
    "    times = np.linspace(-0.15, 0, 72)\n",
    "elif 'duringstim' in splits[0]:\n",
    "    times = np.linspace(0, 0.15, 72)\n",
    "else:\n",
    "    times = np.linspace(-0.4, -0.1, 144)\n",
    "\n",
    "    \n",
    "for split in splits:\n",
    "    try:\n",
    "        r = np.load(Path(pth_res,f'd_with_controls_{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "    except BaseException:\n",
    "        print(\"error:\", split)\n",
    "        continue\n",
    "        \n",
    "    fig, axs = plt.subplots(1,2, sharey=True, figsize=(7,4), dpi=250, \n",
    "                            gridspec_kw={'width_ratios': [6, 1]})\n",
    "    controls = []\n",
    "    for i in range(20):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        color = 'gray'\n",
    "        axs[0].plot(times, r[i], c = color, alpha=0.2)\n",
    "        controls.append(r[i])\n",
    "        \n",
    "    axs[0].plot(times, r[0], c = 'b')\n",
    "    # axs[0].set_title(reg)\n",
    "    # axs[0].set(xlabel='Time(s)')\n",
    "    # axs[0].set(ylabel='Euclidean Distance')\n",
    "    axs[1].hist([np.max(r[k]) for k in r if k != 0], density=True, bins=20, \n",
    "                color = 'silver', orientation='horizontal')\n",
    "    axs[1].axhline(y=np.max(r[0]), c='b')\n",
    "    # axs[1].set(xlabel='Density')\n",
    "    \n",
    "    # Calculate Significant Fraction\n",
    "    p = []\n",
    "    for i in range(len(r[0])): # counting time bins\n",
    "        a = 0\n",
    "        for j in range(len(r)-1): # counting number of trajectories\n",
    "            a+=int(r[0][i]<r[j+1][i])\n",
    "        p.append(a/len(r))\n",
    "    p = np.array(p)\n",
    "    sig_frac = sum(p < 0.05)/len(p)\n",
    "    print(split, np.min(p), 'sig_frac:', sig_frac)\n",
    "\n",
    "    # Print p value\n",
    "    d = np.load(Path(pth_res,f'{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "    p_val_at_max = d['p_euc_c1']\n",
    "    axs[0].text(0.55, 0.97, f'p_val {p_val_at_max:.3f}', transform=axs[0].transAxes,\n",
    "            color='red', fontsize=14, ha='left', va='top')\n",
    "    \n",
    "    for ax in axs:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_facecolor('none')\n",
    "        ax.tick_params(labelsize=15)\n",
    "    axs[0].set_xticks(np.linspace(times[0], times[-1], 4))\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].tick_params(axis='y', left=False, labelleft=False)\n",
    "    axs[1].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    save_dir = '/Users/ariliu/Desktop/ibl-figures'\n",
    "    fig.savefig(f'{save_dir}/{reg}_{split}_dist.pdf', \n",
    "                transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "bca8168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regional_distance(reg, split, time, ptype='p_mean_c', alpha=0.05, plot_p_per_time=True):\n",
    "    if 'duringchoice' in time:\n",
    "        times = np.linspace(-0.15, 0, 72)\n",
    "    elif 'duringstim1' in time:\n",
    "        times = np.linspace(0, 0.08, 42)\n",
    "    elif 'duringstim' in time:\n",
    "        times = np.linspace(0, 0.15, 72)\n",
    "    else:\n",
    "        times = np.linspace(-0.4, -0.1, 144)\n",
    "\n",
    "    if 'combined' in split:\n",
    "        r = np.load(Path(pth_res, f'{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "        r = np.concatenate([r[0].reshape(1, -1), r[1]], axis=0)\n",
    "        split_name = split.split('regde_', 1)[1]\n",
    "        d = np.load(Path(pth_res, f'combined_{split_name}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "    else:\n",
    "        r = np.load(Path(pth_res, f'{split}_regde.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "        d = np.load(Path(pth_res, f'{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(6, 4), dpi=250,\n",
    "                            gridspec_kw={'width_ratios': [6, 1]})\n",
    "    for i in range(1, 40):\n",
    "        if 'duringstim' in time:\n",
    "            axs[0].plot(times[:5], r[i][:5], c='#5f7ea3', alpha=0.5, linewidth=0.5)\n",
    "            axs[0].plot(times[4:], r[i][4:], c='gray', alpha=0.2, linewidth=0.5)\n",
    "        else:\n",
    "            axs[0].plot(times, r[i], c='gray', alpha=0.2, linewidth=0.5)\n",
    "\n",
    "    # axs[0].plot(times, d['d_euc'], c='gold', linewidth=1)\n",
    "    if 'duringstim' in time:\n",
    "        axs[0].plot(times[:5], r[0][:5], c='blue', linewidth=1)\n",
    "        axs[0].plot(times[4:], r[0][4:], c='black', linewidth=1)\n",
    "    else:\n",
    "        axs[0].plot(times, r[0], c='black', linewidth=1)\n",
    "\n",
    "\n",
    "    p_per_time = np.mean(r >= r[0], axis=0)\n",
    "    # # Perform Bonferroni FDR correction\n",
    "    # corrected_p_values = multipletests(p_per_time, alpha=0.05, method='fdr_bh')[1]\n",
    "    # p_per_time = corrected_p_values\n",
    "    \n",
    "    # Calculate p_val for the mean of the first 5 datapoints\n",
    "    mean_first5 = np.mean(r[:, :5], axis=1)\n",
    "    p_val_first5 = np.mean(mean_first5 >= mean_first5[0])\n",
    "\n",
    "    p_val = d[ptype]\n",
    "    # if ptype == 'p_amp':\n",
    "    #     amplitude = np.max(r, axis=1) - np.min(r, axis=1)\n",
    "    #     p_val = np.mean(amplitude >= amplitude[0])\n",
    "    # elif ptype == 'p_mean':\n",
    "    #     p_val = np.mean(np.mean(r, axis=1) >= np.mean(r[0]))\n",
    "    # elif ptype == 'p_max':\n",
    "    #     p_val = np.mean(np.max(r, axis=1) >= np.max(r[0]))\n",
    "    # else:\n",
    "    #     raise ValueError(f\"Invalid ptype: {ptype}\")\n",
    "\n",
    "    if plot_p_per_time:\n",
    "        # ax2 = axs[0].twinx()\n",
    "        # ax2.plot(times, p_per_time, color='blue', linestyle='--', linewidth=1, label='p per time')\n",
    "        # ax2.set_ylim([0, 1])\n",
    "        # ax2.set_ylabel('p', fontsize=10, color='blue')\n",
    "        # ax2.tick_params(axis='y', labelcolor='blue', labelsize=8)\n",
    "\n",
    "        sig_mask = p_per_time <= alpha\n",
    "        axs[0].scatter(times[sig_mask], np.full(np.sum(sig_mask), axs[0].get_ylim()[0]),\n",
    "                       marker='v', color='blue', s=20, zorder=5)\n",
    "\n",
    "    if 'p_mean' in ptype:\n",
    "        axs[1].hist(np.mean(r[1:], axis=1), density=True, bins=20,\n",
    "                    color='silver', orientation='horizontal')\n",
    "        axs[1].axhline(y=np.mean(r[0]), c='black')\n",
    "        if 'duringstim' in time:\n",
    "            axs[1].hist(np.mean(r[1:, :5], axis=1), density=True, bins=20,\n",
    "                        color='#5f7ea3', orientation='horizontal', alpha=0.5)\n",
    "            axs[1].axhline(y=np.mean(r[0, :5]), c='blue')\n",
    "    elif 'p_amp' in ptype:\n",
    "        amplitude = np.max(r, axis=1) - np.min(r, axis=1)\n",
    "        axs[1].hist(amplitude[1:], density=True, bins=20,\n",
    "                    color='silver', orientation='horizontal')\n",
    "        axs[1].axhline(y=amplitude[0], c='black')\n",
    "    elif 'p_max' in ptype:\n",
    "        axs[1].hist(np.max(r[1:], axis=1), density=True, bins=20,\n",
    "                    color='silver', orientation='horizontal')\n",
    "        axs[1].axhline(y=np.max(r[0]), c='black')\n",
    "\n",
    "    axs[0].text(0.2, 0.97, f'p_val {p_val:.4f}', transform=axs[0].transAxes,\n",
    "                color='red' if p_val <= alpha else 'black', fontsize=20, ha='left', va='top')\n",
    "    if 'duringstim' in time:\n",
    "        axs[0].text(0.45, 0.15, f'p_val_offset {p_val_first5:.3f}', transform=axs[0].transAxes,\n",
    "                    color='red' if p_val_first5 <= alpha else 'blue', fontsize=16, ha='left', va='top')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_facecolor('none')\n",
    "        ax.tick_params(labelsize=15)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].tick_params(axis='y', left=False)\n",
    "    if 'duringstim1' in time:\n",
    "        axs[0].set_xticks(np.linspace(times[0], times[-1], 3))\n",
    "    else:\n",
    "        axs[0].set_xticks(np.linspace(times[0], times[-1], 4))\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].tick_params(axis='y', left=False, labelleft=False)\n",
    "    axs[1].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    save_dir = '/Users/ariliu/Desktop/ibl-figures'\n",
    "    if 'combined' in split:\n",
    "        fig.savefig(f'{save_dir}/{reg}_{time}_{ptype}_dist.pdf', \n",
    "                    transparent=True)\n",
    "    else:\n",
    "        fig.savefig(f'{save_dir}/{reg}_{split}_{ptype}_dist.pdf', \n",
    "                transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regional_distance_comparison(reg, times):\n",
    "    x_times = np.linspace(0, 0.15, 72)\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(6, 4), dpi=150)\n",
    "    for time in times:\n",
    "        splits = run_align[time]\n",
    "        name = \"_\".join(splits)\n",
    "        r = np.load(Path(pth_res, f'combined_regde_{name}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "        r = np.concatenate([r[0].reshape(1, -1), r[1]], axis=0)\n",
    "        # d = np.load(Path(pth_res, f'combined_{name}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "        # print(time, 'amp_slope', d['amp_slope'], 'amp_loc', d['amp_loc'])\n",
    "\n",
    "        axs.plot(x_times, r[0], linewidth=1, label=time)\n",
    "        axs.scatter(x_times, r[0], color='black', s=10)  # Add dots for each datapoint\n",
    "\n",
    "    axs.spines['top'].set_visible(False)\n",
    "    axs.spines['right'].set_visible(False)\n",
    "    axs.set_xticklabels([])\n",
    "    # ax.set_yticklabels([])\n",
    "    axs.set_facecolor('none')\n",
    "    axs.tick_params(labelsize=15)\n",
    "    # axs[0].spines['left'].set_visible(False)\n",
    "    # axs[0].tick_params(axis='y', left=False)\n",
    "\n",
    "    axs.set_xticks(np.linspace(x_times[0], x_times[-1], 4))\n",
    "    axs.legend(fontsize=15, frameon=False)\n",
    "    axs.set_title(reg, fontsize=15)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    save_dir = '/Users/ariliu/Desktop/ibl-figures'\n",
    "    fig.savefig(f'{save_dir}/{reg}_{times}_comparison.pdf', \n",
    "                transparent=True)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 'PRNr'\n",
    "ptype = 'p_mean_c'\n",
    "\n",
    "# timeframes = ['block_duringstim', 'choice_duringstim0', 'block_duringchoice', 'choice_duringchoice0']\n",
    "# timeframes = ['stim_duringstim0', 'choice_duringstim0', 'stim_duringchoice0', 'choice_duringchoice0']\n",
    "timeframes=['choice_duringstim0']\n",
    "for timeframe in timeframes:    \n",
    "    splits = run_align[timeframe]\n",
    "    if len(splits) == 1:\n",
    "        combined_name = splits[0]\n",
    "    else:\n",
    "        combined_name = 'combined_regde_'+\"_\".join(splits)\n",
    "\n",
    "    # for split in splits:\n",
    "    #     print(split)\n",
    "    #     plot_regional_distance(reg, split, timeframe, ptype=ptype, plot_p_per_time=True)\n",
    "    plot_regional_distance(reg, combined_name, timeframe, ptype=ptype, alpha=0.05, plot_p_per_time=True)\n",
    "\n",
    "# plot_regional_distance(reg, 'block_only', timeframe, ptype=ptype, plot_p_per_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6548404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg='SIM'\n",
    "ptype = 'p_mean_c'\n",
    "\n",
    "timeframe='stim_duringchoice0'\n",
    "splits = run_align[timeframe]\n",
    "combined_name = 'combined_regde_'+\"_\".join(splits)\n",
    "\n",
    "# regs = ['GRN', 'MRN', 'IRN']\n",
    "regs = ['MOs', 'SIM', 'IP', 'RN', 'APN', 'SCm', \n",
    "            #    'PF'\n",
    "               ]\n",
    "\n",
    "# regs = ['GRN', 'GPi', 'SNr']\n",
    "# regs = ['SIM', \n",
    "#             #    'DEC', \n",
    "#                'CLA', \n",
    "#                'PCG', \n",
    "#             #    'SSs', \n",
    "#                'ACAd', 'MOs', 'RN', 'SMT']\n",
    "\n",
    "for reg in regs:\n",
    "    plot_regional_distance(reg, combined_name, timeframe, ptype=ptype, plot_p_per_time=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f99a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_distance_over_regions(regs, timewindow, split=None, alpha=0.05, \n",
    "                                       ptype='p_mean_c', plot_p_per_time=True):\n",
    "    if 'duringchoice' in timewindow:\n",
    "        times = np.linspace(-0.15, 0, 72)\n",
    "    elif 'duringstim' in timewindow:\n",
    "        times = np.linspace(0, 0.15, 72)\n",
    "    else:\n",
    "        times = np.linspace(-0.4, -0.1, 144)\n",
    "\n",
    "    if split is None:\n",
    "        splits = run_align[timewindow]\n",
    "        split = 'combined_regde_'+\"_\".join(splits)\n",
    "\n",
    "    all_r = []\n",
    "    all_d = []\n",
    "\n",
    "    if 'GRN' in regs:\n",
    "        c = 'tomato'\n",
    "    elif 'MOs' in regs:\n",
    "        c = 'gold'\n",
    "    else:\n",
    "        c = 'blue'\n",
    "\n",
    "    for reg in regs:\n",
    "        if 'combined' in split:\n",
    "            r = np.load(Path(pth_res, f'{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "            r = np.concatenate([r[0].reshape(1, -1), r[1]], axis=0)\n",
    "            split_name = split.split('regde_', 1)[1]\n",
    "            d = np.load(Path(pth_res, f'combined_{split_name}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "        else:\n",
    "            r = np.load(Path(pth_res, f'{split}_regde.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "            d = np.load(Path(pth_res, f'combined_{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "\n",
    "        all_r.append(r)\n",
    "        all_d.append(d)\n",
    "\n",
    "    # average across regions (shape: [n_samples, time])\n",
    "    r_avg = np.mean(np.stack(all_r), axis=0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(7, 4), dpi=250,\n",
    "                            gridspec_kw={'width_ratios': [6, 1]})\n",
    "    for i in range(1, min(40, r_avg.shape[0])):\n",
    "        axs[0].plot(times, r_avg[i], c='gray', alpha=0.2, linewidth=0.5)\n",
    "\n",
    "    axs[0].plot(times, r_avg[0], c=c, linewidth=1)\n",
    "\n",
    "    # p-value curve (per time) and aggregate\n",
    "    p_per_time = np.mean(r_avg >= r_avg[0], axis=0)\n",
    "\n",
    "    # Calculate p_val for the mean of the first 5 datapoints\n",
    "    mean_first5 = np.mean(r[:, :5], axis=1)\n",
    "    p_val_first5 = np.mean(mean_first5 >= mean_first5[0])\n",
    "\n",
    "    if ptype.endswith('_c'):\n",
    "        p_val = np.mean([d[ptype] for d in all_d])\n",
    "    elif ptype == 'p_mean':\n",
    "        p_val = np.mean(np.mean(r_avg[1:], axis=1) >= np.mean(r_avg[0]))\n",
    "    elif ptype == 'p_amp':\n",
    "        amp = np.max(r_avg, axis=1) - np.min(r_avg, axis=1)\n",
    "        p_val = np.mean(amp[1:] >= amp[0])\n",
    "    elif ptype == 'p_max':\n",
    "        p_val = np.mean(np.max(r_avg[1:], axis=1) >= np.max(r_avg[0]))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ptype: {ptype}\")\n",
    "\n",
    "    if plot_p_per_time:\n",
    "        ax2 = axs[0].twinx()\n",
    "        ax2.plot(times, p_per_time, color='blue', linestyle='--', linewidth=1, label='p per time')\n",
    "        ax2.set_ylim([0, 1])\n",
    "        ax2.set_ylabel('p', fontsize=10, color='blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='blue', labelsize=8)\n",
    "\n",
    "        sig_mask = p_per_time <= alpha\n",
    "        axs[0].scatter(times[sig_mask], np.full(np.sum(sig_mask), axs[0].get_ylim()[0]),\n",
    "                       marker='v', color='blue', s=20, zorder=5)\n",
    "\n",
    "    if 'p_mean' in ptype:\n",
    "        axs[1].hist(np.mean(r_avg[1:], axis=1), density=True, bins=20,\n",
    "                    color='silver', orientation='horizontal')\n",
    "        axs[1].axhline(y=np.mean(r_avg[0]), c='black')\n",
    "    elif 'p_amp' in ptype:\n",
    "        amp = np.max(r_avg, axis=1) - np.min(r_avg, axis=1)\n",
    "        axs[1].hist(amp[1:], density=True, bins=20,\n",
    "                    color='silver', orientation='horizontal')\n",
    "        axs[1].axhline(y=amp[0], c='black')\n",
    "    elif 'p_max' in ptype:\n",
    "        axs[1].hist(np.max(r_avg[1:], axis=1), density=True, bins=20,\n",
    "                    color='silver', orientation='horizontal')\n",
    "        axs[1].axhline(y=np.max(r_avg[0]), c='black')\n",
    "\n",
    "    axs[0].text(0.2, 0.97, f'p_val {p_val:.3f}', transform=axs[0].transAxes,\n",
    "                color='red' if p_val <= alpha else 'black', fontsize=18, ha='left', va='top')\n",
    "    axs[0].text(0.2, 0.85, f'p_val_offset {p_val_first5:.3f}', transform=axs[0].transAxes,\n",
    "                color='red' if p_val_first5 <= alpha else 'black', fontsize=15, ha='left', va='top')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_facecolor('none')\n",
    "        ax.tick_params(labelsize=15)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].tick_params(axis='y', left=False)\n",
    "\n",
    "    axs[0].set_xticks(np.linspace(times[0], times[-1], 4))\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].tick_params(axis='y', left=False, labelleft=False)\n",
    "    axs[1].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    save_dir = '/Users/ariliu/Desktop/ibl-figures'\n",
    "    fig.savefig(f'{save_dir}/{\"_\".join(regs)}_{split}_{ptype}_dist_avg.pdf', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group_comparison_over_regions(regs_int, regs_choice, timeframe, alpha=0.05, ptype='p_mean_c',\n",
    "                                       label_A='integrator', label_B='choice'):\n",
    "\n",
    "    splits = run_align[timeframe]\n",
    "    split = 'combined_'+\"_\".join(splits)\n",
    "\n",
    "    if 'duringchoice' in split:\n",
    "        times = np.linspace(-0.15, 0, 72)\n",
    "    elif 'duringstim' in split:\n",
    "        times = np.linspace(0, 0.15, 72)\n",
    "    else:\n",
    "        times = np.linspace(-0.4, -0.1, 144)\n",
    "\n",
    "    def load_group(regs):\n",
    "        all_r = []\n",
    "        res = manifold_to_csv(split, alpha, ptype)\n",
    "        for reg in regs:\n",
    "            sig = res[res['region']==reg]['significant'].iloc[0]\n",
    "            if sig==1:\n",
    "                r = np.load(Path(pth_res, f'{split}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "                print(reg)\n",
    "                all_r.append(r['d_euc'])\n",
    "        return np.mean(np.stack(all_r), axis=0)  # shape: (n_samples, time)\n",
    "\n",
    "    print('int regs')\n",
    "    r_int = load_group(regs_int)\n",
    "    print('move regs')\n",
    "    r_choice = load_group(regs_choice)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=250)\n",
    "\n",
    "    ax.plot(times, r_int, color='gold', linewidth=2, label=label_A)\n",
    "    ax.plot(times, r_choice, color='tomato', linewidth=2, label=label_B)\n",
    "\n",
    "    ax.set_xticks(np.linspace(times[0], times[-1], 4))\n",
    "    # ax.set_xlabel('Time (s)')\n",
    "    # ax.set_ylabel('Euclidean Distance')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_facecolor('none')\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    # ax.legend(frameon=False, fontsize=10, loc='upper left')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    save_dir = '/Users/ariliu/Desktop/ibl-figures'\n",
    "    fig.savefig(f'{save_dir}/compare_int_choice_{timeframe}.pdf', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ['stim_duringstim0', 'choice_duringstim0', 'stim_duringchoice0', 'choice_duringchoice0']\n",
    "ptype = 'p_mean_c'\n",
    "alpha = 0.05\n",
    "sc_threshold = 0.6\n",
    "\n",
    "res = get_sc_table(times, ptype, alpha, combined_p=True, \n",
    "                   sc_threshold=sc_threshold)\n",
    "regs = res['region']\n",
    "\n",
    "for timeframe in ['duringstim', 'duringchoice']:\n",
    "\n",
    "    # regs_int = list(regs[res[f'sc_{timeframe}_int_mov']==0.5])\n",
    "    # regs_move = list(regs[res[f'sc_{timeframe}_int_mov']==1])\n",
    "    regs_move = list(set(move_regs_stim) | set(move_regs_choice))\n",
    "    regs_int = list(set(int_regs_stim) | set(int_regs_choice))\n",
    "\n",
    "    # print(regs_move)\n",
    "\n",
    "    plot_group_comparison_over_regions(regs_int, regs_move, f'act_block_{timeframe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "4cf9ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regs_stim = ['ZI', 'VISp', 'LP']\n",
    "# regs_int = ['SIM', 'CUL4 5', 'BMA', 'NTS', 'PRNc', 'PARN', 'SUV', 'MV', 'PRNr',\n",
    "#         'PAR', 'MOs', 'APN', 'SCm', 'PPN']\n",
    "# regs_move = [\n",
    "#              'CENT2', 'IP', 'CENT3', 'CP', 'GRN', 'V', 'IRN', 'RN', 'MRN',\n",
    "#              'GPi'\n",
    "#              ]\n",
    "\n",
    "# get stim, move, int regs by running plot_combined_onetype\n",
    "# move_regs_stim, move_regs_choice, int_regs_stim, int_regs_choice, stim_regs\n",
    "\n",
    "# timeframe='act_block_duringstim'\n",
    "timeframe='choice_duringchoice0'\n",
    "# timeframe='act_block_duringchoice'\n",
    "ptype='p_mean_c'\n",
    "\n",
    "# timeframe='intertrial'\n",
    "\n",
    "regs = int_regs_stim\n",
    "splits = run_align[timeframe]\n",
    "combined_name = 'combined_regde_'+\"_\".join(splits)\n",
    "\n",
    "# plot_average_distance_over_regions(regs, timeframe, plot_p_per_time=False)\n",
    "\n",
    "for reg in regs:\n",
    "    plot_regional_distance(reg, combined_name, timeframe, ptype=ptype, alpha=0.05, plot_p_per_time=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f80f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_plots(meta_split, regs, color, p_type=None, restr=True):\n",
    "    '''\n",
    "    plot average all detailed splits' trajectories during a timeframe\n",
    "    restr: restricted to only correct trials\n",
    "    '''\n",
    "    \n",
    "    splits = meta_splits[meta_split]\n",
    "    if restr:\n",
    "        splits = splits[:2]\n",
    "    d = {}\n",
    "    for split in splits:\n",
    "        d[split] = 0\n",
    "        for reg in regs:\n",
    "            r = np.load(Path(pth_res,f'{split}.npy'),\n",
    "                        allow_pickle=True).flat[0][reg]\n",
    "            if p_type==None:\n",
    "                d[split] += r['d_euc']\n",
    "            else:\n",
    "                r['significant'] = r[p_type]<sigl\n",
    "                d[split] += r['d_euc'] * r['significant']\n",
    "\n",
    "    d = pd.DataFrame(data=d)\n",
    "    d['sum'] = d[splits].apply(np.sum, axis=1)\n",
    "\n",
    "    xx = np.linspace(-pre_post[meta_split][0], \n",
    "                                  pre_post[meta_split][1], \n",
    "                                  len(d['sum']))\n",
    "    yy = d['sum']/len(regs)\n",
    "    plt.plot(xx,yy,c=color)\n",
    "    \n",
    "    \n",
    "def get_multiple_line_plots(metasplits, reg, labels, p_type=None):\n",
    "    \"\"\"\n",
    "    plot all detailed splits' trajectories during a timeframe\n",
    "    average over correct & incorrect trials (probably not useful)\n",
    "    \"\"\"\n",
    "\n",
    "    col = ['b', 'r', 'y', 'g', 'c', 'orange']\n",
    "    for meta_split in metasplits:\n",
    "        splits = meta_splits[meta_split]\n",
    "        d = {}\n",
    "        for split in splits:\n",
    "            r = np.load(Path(pth_res,f'{split}.npy'),\n",
    "                        allow_pickle=True).flat[0][reg]\n",
    "            if p_type==None:\n",
    "                d[split] = r['d_euc']\n",
    "            else:\n",
    "                r['significant'] = r[p_type]<sigl\n",
    "                d[split] = r['d_euc'] * r['significant']\n",
    "\n",
    "        xx = np.linspace(-pre_post[meta_split][0], \n",
    "                         pre_post[meta_split][1], \n",
    "                         len(d[split]))\n",
    "        for i in range(0,6):\n",
    "            yy = (d[splits[i]] + d[splits[i+6]]) / 2\n",
    "            plt.plot(xx,yy, c = col[i])\n",
    "        \n",
    "    plt.legend(labels)\n",
    "    plt.title(reg)\n",
    "\n",
    "    \n",
    "def get_multiple_line_plots_0(metasplits, reg, labels, p_type=None):\n",
    "    \"\"\"\n",
    "    plot detailed splits' trajectories during a timeframe\n",
    "    restricted to correct/incorrect subset of trials only\n",
    "    \"\"\"\n",
    "    \n",
    "    #col = sns.color_palette('flare', 6)\n",
    "    col = ['#e3685c', '#e98d6b', '#b13c6c', '#8f3371', '#d14a61', '#6c2b6d']\n",
    "    for meta_split in metasplits:\n",
    "        splits = meta_splits[meta_split]\n",
    "        d = {}\n",
    "        i = 0\n",
    "        for split in splits:\n",
    "            r = np.load(Path(pth_res,f'{split}.npy'),\n",
    "                        allow_pickle=True).flat[0][reg]\n",
    "            if p_type==None:\n",
    "                d[split] = r['d_euc']\n",
    "            else:\n",
    "                r['significant'] = r[p_type]<sigl\n",
    "                d[split] = r['d_euc'] * r['significant']\n",
    "\n",
    "            xx = np.linspace(-pre_post[meta_split][0], \n",
    "                         pre_post[meta_split][1], \n",
    "                         len(d[split]))\n",
    "            yy = d[split]\n",
    "            plt.plot(xx,yy, c = col[i])\n",
    "            i+=1\n",
    "        \n",
    "    #plt.legend(labels)\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Euclidean Distance')\n",
    "    plt.title(reg)\n",
    "    xticks = [0,0.05,0.1,0.15,0.2,0.25,0.3,0.35]\n",
    "    ticklabels = ['0','0.05','0.1','0.15','-0.15','-0.1','-0.05','0']\n",
    "    plt.xticks(xticks, ticklabels)\n",
    "    plt.savefig('/Users/ariliu/Desktop/'+reg+'_lineplots.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d594cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_type = None #'p_euc_c1' 'p_euc'\n",
    "reg = 'GRN'\n",
    "\n",
    "labels = ['block difference, choice R', 'block difference, choice L',\n",
    "          'choice difference, block L', 'choice difference, block R',\n",
    "          'discordant, different block & choice', 'concordant, different block & choice'\n",
    "         ]\n",
    "\n",
    "#metasplits = ['intertrial_all_0', 'duringstim_all_0', 'duringchoice_all_0']\n",
    "metasplits = ['duringstim_all_0', 'duringchoice_all_0']\n",
    "#metasplits = ['duringstim_subset', 'duringchoice_subset']\n",
    "get_multiple_line_plots_0(metasplits, reg, labels, p_type)\n",
    "\n",
    "#metasplits = ['duringstim_all', 'duringchoice_all']\n",
    "#metasplits = ['intertrial_all', 'duringstim_all', 'duringchoice_all']\n",
    "#get_multiple_line_plots(metasplits, reg, labels, p_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9108a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrand = 2000\n",
    "\n",
    "p_type = 'p_euc_c1' #None #'p_euc'\n",
    "regs_c = ['GRN','PAG','AIv','MOp','RSPagl', 'CENT3'] #'AIv','MOp','RSPagl'\n",
    "regs_s = ['IRN','MOs','MRN','CENT3']\n",
    "regs = regs_c\n",
    "colors = {\n",
    "    'c':'tomato',\n",
    "    's':'gold'\n",
    "}\n",
    "color = colors['c']\n",
    "\n",
    "meta_split = 'duringchoice'\n",
    "splits = meta_splits[meta_split]\n",
    "splits = splits[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "n=0\n",
    "for split in splits:\n",
    "    for reg in regs:\n",
    "        r = np.load(Path(pth_res,f'{split}.npy'),\n",
    "                    allow_pickle=True).flat[0][reg]\n",
    "        regde = np.load(Path(pth_res,f'{split}_regde.npy'),\n",
    "                    allow_pickle=True).flat[0][reg]\n",
    "        r['significant'] = r[p_type]<sigl\n",
    "        n+=1 if r['significant'] else 0\n",
    "        if 'true' not in d:\n",
    "            d['true'] = np.zeros_like(regde[0], dtype=float) \n",
    "        d['true'] += regde[0] * r['significant']\n",
    "        for i in range(len(regde[1:])):\n",
    "            key = f'ctrl_{i}'\n",
    "            if key not in d:\n",
    "                d[key] = np.zeros_like(regde[i+1], dtype=float)\n",
    "            d[key] += regde[i+1] * r['significant']\n",
    "            \n",
    "d['true'] = d['true']/n\n",
    "for i in range(nrand):\n",
    "    d[f'ctrl_{i}'] = d[f'ctrl_{i}']/n\n",
    "\n",
    "xx = np.linspace(-pre_post[meta_split][0], \n",
    "                                pre_post[meta_split][1], \n",
    "                                len(d['true']))\n",
    "yy = d['true']\n",
    "plt.plot(xx,yy,c=color)\n",
    "for i in range(nrand):\n",
    "    plt.plot(xx, d[f'ctrl_{i}']/n, c='gray', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3731af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot avg block L-R distance for stim integrators vs choice generators\n",
    "\n",
    "p_type = 'p_euc_c1' #None #'p_euc'\n",
    "regs_c = ['GRN','PAG','AIv','MOp','RSPagl', 'CENT3'] #'AIv','MOp','RSPagl'\n",
    "regs_s = ['IRN','MOs','MRN','CENT3']\n",
    "regs = {\n",
    "    'c':regs_c,\n",
    "    's':regs_s\n",
    "}\n",
    "colors = {\n",
    "    'c':'tomato',\n",
    "    's':'gold'\n",
    "}\n",
    "\n",
    "\n",
    "for regtype in ['c','s']:\n",
    "    for meta_split in ['duringstim', 'duringchoice']: #'intertrial'\n",
    "        get_line_plots(meta_split, regs[regtype], colors[regtype], p_type)\n",
    "        \n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Average Block L-R Euclidean Distance')\n",
    "xticks = [0,0.05,0.1,0.15,0.2,0.25,0.3,0.35]\n",
    "ticklabels = ['0','0.05','0.1','0.15','-0.15','-0.1','-0.05','0']\n",
    "plt.xticks(xticks, ticklabels)\n",
    "plt.savefig('/Users/ariliu/Desktop/avgd.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sc_line_plots(sc_splits, reg, stype=None, p_type=None):\n",
    "    \n",
    "    for meta_split in sc_splits:\n",
    "        splits = meta_splits[meta_split]\n",
    "        r0 = np.load(Path(pth_res,f'{splits[0]}.npy'),\n",
    "                    allow_pickle=True).flat[0][reg]\n",
    "        r1 = np.load(Path(pth_res,f'{splits[1]}.npy'),\n",
    "                    allow_pickle=True).flat[0][reg]\n",
    "\n",
    "        if p_type==None:\n",
    "                d = r1['d_euc'] / (r0['d_euc'] + r1['d_euc'])\n",
    "        else:\n",
    "                r0['significant'] = r0[p_type]<sigl\n",
    "                r1['significant'] = r1[p_type]<sigl\n",
    "                d = r1['d_euc'] * r1['significant'] / (\n",
    "                    r0['d_euc'] * r0['significant'] + r1['d_euc'] * r1['significant'])\n",
    "\n",
    "        xx = np.linspace(-pre_post[meta_split][0], \n",
    "                                  pre_post[meta_split][1], \n",
    "                                  len(d))\n",
    "        yy = d\n",
    "        plt.plot(xx,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411be31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sc_splits = ['sc_duringstim', 'sc_duringchoice']\n",
    "get_sc_line_plots(sc_splits, 'MV', 'p_euc_c1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402091a",
   "metadata": {},
   "source": [
    "## process data p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d504934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amp_slope(timeframe, n=10):\n",
    "    '''\n",
    "    for stim/choice splits, locate the peak of the amplitude and fit the slope of the last n points\n",
    "    used later for region type classification\n",
    "    n: number of last points to fit the slope\n",
    "    '''\n",
    "\n",
    "    splits = run_align[timeframe]\n",
    "    if len(splits) == 1:\n",
    "        combined_name = splits[0]\n",
    "        combined_regde_name = f'{combined_name}_regde'\n",
    "    else:\n",
    "        combined_name = 'combined_'+\"_\".join(splits)\n",
    "        combined_regde_name = 'combined_regde_'+\"_\".join(splits)\n",
    "\n",
    "    # run for combined results\n",
    "    d = np.load(Path(pth_res, f'{combined_name}.npy'), \n",
    "                    allow_pickle=True).flat[0]  \n",
    "    regs = [x for x in d]\n",
    "    for reg in regs:\n",
    "        r = np.load(Path(pth_res, f'{combined_regde_name}.npy'), allow_pickle=True).flatten()[0][reg][0]\n",
    "        slope = np.polyfit(np.linspace(0, 0.15, len(r)), r, 1)[0]\n",
    "        d[reg]['amp_slope'] = slope\n",
    "        \n",
    "        slope_last = np.polyfit(np.arange(n), r[-n:], 1)[0]\n",
    "        d[reg]['slope_last'] = slope_last\n",
    "\n",
    "        amp_loc = np.argmax(r)\n",
    "        d[reg]['amp_loc'] = amp_loc\n",
    "\n",
    "        slope_last_5 = np.polyfit(np.arange(5), r[-5:], 1)[0]\n",
    "        d[reg]['slope_last_5'] = slope_last_5\n",
    "\n",
    "        \n",
    "    np.save(Path(pth_res, f'{combined_name}.npy'), d, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15aabe18",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ariliu/Downloads/ONE/openalyx.internationalbrainlab.org/manifold/res/combined_act_stim_block_l_act_stim_block_r.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# for timeframe in run_align:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m timeframe \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact_stim_duringstim1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact_choice_duringstim0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact_stim_duringstim0\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact_stim_duringchoice0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact_choice_duringchoice0\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mcompute_amp_slope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m, in \u001b[0;36mcompute_amp_slope\u001b[0;34m(timeframe, n)\u001b[0m\n\u001b[1;32m     14\u001b[0m     combined_regde_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_regde_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(splits)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# run for combined results\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpth_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcombined_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflat[\u001b[38;5;241m0\u001b[39m]  \n\u001b[1;32m     19\u001b[0m regs \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m d]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reg \u001b[38;5;129;01min\u001b[39;00m regs:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iblenv/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ariliu/Downloads/ONE/openalyx.internationalbrainlab.org/manifold/res/combined_act_stim_block_l_act_stim_block_r.npy'"
     ]
    }
   ],
   "source": [
    "# for timeframe in run_align:\n",
    "for timeframe in ['act_stim_duringstim1', 'act_choice_duringstim0', 'act_stim_duringstim0', \n",
    "                  'act_stim_duringchoice0', 'act_choice_duringchoice0']:\n",
    "    compute_amp_slope(timeframe, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8f3fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr_combined(timeframe, ptype='p_euc', sigl=0.05):\n",
    "    \n",
    "    '''\n",
    "    FDR correction, based on regions (same as in bwm analysis)\n",
    "    results saved as '{ptype}_c'\n",
    "    '''\n",
    "    splits = run_align[timeframe]\n",
    "    if len(splits) == 1:\n",
    "        combined_name = splits[0]\n",
    "    else:\n",
    "        combined_name = 'combined_'+\"_\".join(splits)\n",
    "\n",
    "    # run correction for combined results\n",
    "    d = np.load(Path(pth_res, f'{combined_name}.npy'), \n",
    "                    allow_pickle=True).flat[0]\n",
    "    regs = [x for x in d]\n",
    "    pvals = [d[x][ptype] for x in d]\n",
    "    _, pvals_c, _, _ = multipletests(pvals, sigl, method='fdr_bh')\n",
    "\n",
    "    for i in range(len(regs)):\n",
    "        d[regs[i]][f'{ptype}_c'] = pvals_c[i]\n",
    "\n",
    "    np.save(Path(pth_res, f'{combined_name}.npy'), d, allow_pickle=True)\n",
    "\n",
    "    # run for each split\n",
    "    if len(splits) > 1:\n",
    "        for split in splits:\n",
    "            d = np.load(Path(pth_res, f'{split}.npy'), \n",
    "                        allow_pickle=True).flat[0]\n",
    "            regs = [x for x in d]\n",
    "            pvals = [d[x][ptype] for x in d]\n",
    "            _, pvals_c, _, _ = multipletests(pvals, sigl, method='fdr_bh')\n",
    "        \n",
    "            for i in range(len(regs)):\n",
    "                d[regs[i]][f'{ptype}_c'] = pvals_c[i]\n",
    "        \n",
    "            np.save(Path(pth_res, f'{split}.npy'), d, allow_pickle=True)\n",
    "\n",
    "\n",
    "def compute_p_value(timeframe, ptype='p_mean'):\n",
    "    splits = run_align[timeframe]\n",
    "    if len(splits) == 1:\n",
    "        combined_name = splits[0]\n",
    "        combined_regde_name = f'{combined_name}_regde'\n",
    "    else:\n",
    "        combined_name = 'combined_'+\"_\".join(splits)\n",
    "        combined_regde_name = 'combined_regde_'+\"_\".join(splits)\n",
    "\n",
    "    # run for combined results\n",
    "    d = np.load(Path(pth_res, f'{combined_name}.npy'), \n",
    "                    allow_pickle=True).flat[0]  \n",
    "    regs = [x for x in d]\n",
    "    for reg in regs:\n",
    "        r = np.load(Path(pth_res, f'{combined_regde_name}.npy'), allow_pickle=True).flatten()[0][reg]\n",
    "        if len(splits) > 1: # for combined splits the control curves are all stored in r[1]\n",
    "            r = np.concatenate([r[0].reshape(1, -1), r[1]], axis=0)\n",
    "        if ptype == 'p_amp':\n",
    "            amplitude = np.max(r, axis=1) - np.min(r, axis=1)\n",
    "            p_val = np.mean(amplitude >= amplitude[0])\n",
    "        elif ptype == 'p_mean':\n",
    "            p_val = np.mean(np.mean(r, axis=1) >= np.mean(r[0]))\n",
    "        elif ptype == 'p_max':\n",
    "            p_val = np.mean(np.max(r, axis=1) >= np.max(r[0]))\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid ptype: {ptype}\")\n",
    "        d[reg][f'{ptype}'] = p_val\n",
    "        \n",
    "    np.save(Path(pth_res, f'{combined_name}.npy'), d, allow_pickle=True)\n",
    "\n",
    "    # run for each split\n",
    "    if len(splits) > 1: \n",
    "        for split in splits:\n",
    "            d = np.load(Path(pth_res, f'{split}.npy'), \n",
    "                        allow_pickle=True).flat[0]\n",
    "            regs = [x for x in d]\n",
    "            for reg in regs:\n",
    "                r = np.load(Path(pth_res, f'{split}_regde.npy'), allow_pickle=True).flat[0][reg]\n",
    "                if ptype == 'p_amp':\n",
    "                    amplitude = np.max(r, axis=1) - np.min(r, axis=1)\n",
    "                    p_val = np.mean(amplitude >= amplitude[0])\n",
    "                elif ptype == 'p_mean':\n",
    "                    p_val = np.mean(np.mean(r, axis=1) >= np.mean(r[0]))\n",
    "                elif ptype == 'p_max':\n",
    "                    p_val = np.mean(np.max(r, axis=1) >= np.max(r[0]))\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid ptype: {ptype}\")\n",
    "                d[reg][f'{ptype}'] = p_val\n",
    "            \n",
    "            np.save(Path(pth_res, f'{split}.npy'), d, allow_pickle=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = [\n",
    "#     'stim_duringstim0', 'choice_duringstim0', \n",
    "#     'stim_duringchoice0', 'choice_duringchoice0'\n",
    "# ]\n",
    "# times = ['stim_duringstim', 'choice_duringstim', 'stim_duringchoice', 'choice_duringchoice']\n",
    "# times = ['block_duringstim', 'block_duringchoice', 'intertrial']\n",
    "times = ['intertrial0_act', 'intertrial_act', 'block_duringstim_act', 'block_duringchoice_act']\n",
    "\n",
    "for ptype in ['p_mean', 'p_amp', 'p_max']:\n",
    "    for timeframe in times:\n",
    "        compute_p_value(timeframe, ptype=ptype)\n",
    "        fdr_combined(timeframe, ptype=ptype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ac596",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe = 'choice_duringstim'\n",
    "splits = run_align[timeframe]\n",
    "combined_name = 'combined_'+\"_\".join(splits)\n",
    "\n",
    "d = np.load(Path(pth_res, f'{combined_name}.npy'), \n",
    "                    allow_pickle=True).flat[0]\n",
    "for reg in ['GRN', 'VISp']:\n",
    "    print(reg)\n",
    "    print(d[reg]['p_mean'])\n",
    "    print(d[reg]['p_mean_c'])\n",
    "    print(d[reg]['p_amp'])\n",
    "    print(d[reg]['p_amp_c'])\n",
    "    print(d[reg]['p_max'])\n",
    "    print(d[reg]['p_max_c'])\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904ffd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manifold_to_csv(split, sigl, p_type):\n",
    "\n",
    "    '''\n",
    "    reformat results for table\n",
    "    '''\n",
    "    \n",
    "    # mapping = 'Beryl'\n",
    "\n",
    "    columns = ['region', #'name', \n",
    "               p_type, 'amp_euc', 'lat_euc', \n",
    "               'amp_slope', 'slope_last', 'amp_loc', 'slope_last_5',\n",
    "               #'amp_euc_can','lat_euc_can', 'amp_eucn_can', 'lat_eucn_can'\n",
    "              ]\n",
    "               \n",
    "    d = np.load(Path(pth_res, f'{split}.npy'), \n",
    "                    allow_pickle=True).flat[0]\n",
    "    \n",
    "    # use a sample to align the regions if sample file exists (easier to align here than later when plotting tables!!)\n",
    "    sample_path = Path(pth_res, f'intertrial.csv')\n",
    "    if not sample_path.exists():\n",
    "        regs = [x for x in d]\n",
    "    else:\n",
    "        sample = pd.read_csv(sample_path)\n",
    "        regs = sample.region\n",
    "\n",
    "    r = []   \n",
    "    for reg in regs:\n",
    "        if reg not in d:\n",
    "            r.append([reg, None, None, None])\n",
    "            continue\n",
    "        r.append([reg, d[reg][p_type],\n",
    "                    d[reg]['amp_euc'], d[reg]['lat_euc'],\n",
    "                    d[reg]['amp_slope'], d[reg]['slope_last'], \n",
    "                    d[reg]['amp_loc'], d[reg]['slope_last_5']\n",
    "                    ])\n",
    "    \n",
    "    df  = pd.DataFrame(data=r, columns=columns)\n",
    "    \n",
    "    df['significant'] = (df[p_type] <= sigl).astype(int)\n",
    "    df.to_csv(Path(pth_res, f'{split}.csv'), index=False) \n",
    "    return df\n",
    "\n",
    "def manifold_to_csv_old(meta_split, sigl, p_type):\n",
    "\n",
    "    '''\n",
    "    reformat results for table\n",
    "    '''\n",
    "                   \n",
    "    splits = meta_splits[meta_split]\n",
    "    # sample = pd.read_pickle('~/Downloads/stim.pkl')\n",
    "    sample = pd.read_csv(Path(pth_res, f'intertrial.csv'))\n",
    "\n",
    "    for split in splits:\n",
    "        r = []\n",
    "        d = np.load(Path(pth_res,f'{split}.npy'),\n",
    "                    allow_pickle=True).flat[0] \n",
    "        \n",
    "        for reg in sample.region:\n",
    "            if reg not in d:\n",
    "                r.append([reg, None, None, None])\n",
    "                continue        \n",
    "        #for reg in d:\n",
    "            r.append([reg, d[reg][p_type],\n",
    "                      d[reg]['amp_euc'], d[reg]['lat_euc'],\n",
    "                     ])\n",
    "        \n",
    "        df  = pd.DataFrame(data=r,\n",
    "                           columns=['region',\n",
    "                                    f'p_{split}', f'amp_{split}',\n",
    "                                    f'lat_{split}'])\n",
    "        \n",
    "        df[f'{split}_significant'] = df[f'p_{split}']<=sigl\n",
    "        df.to_csv(Path(pth_res, f'{split}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9ed17",
   "metadata": {},
   "source": [
    "## plot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692ddd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_tables import get_cmap_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a87f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_table_with_styles(df, beryl_palette, colormap_lookup, out_path):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # n_rows, n_cols = df.shape\n",
    "    # fig, ax = plt.subplots(figsize=(0.4 * n_cols, 0.27 * n_rows))\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=df.values,\n",
    "        colLabels=df.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center'\n",
    "    )\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(7)\n",
    "    table.scale(1.2, 1.3)\n",
    "\n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        is_header = row == 0\n",
    "        col_name = df.columns[col] if not is_header else None\n",
    "\n",
    "        # header row\n",
    "        if is_header:\n",
    "            cell.set_text_props(weight='bold', fontsize=7)\n",
    "            cell.set_facecolor('none')          # transparent background\n",
    "            cell.get_text().set_rotation(270)\n",
    "            cell.set_linewidth(0)              # remove border line\n",
    "            cell.get_text().set_verticalalignment('bottom')\n",
    "            cell.get_text().set_horizontalalignment('center')\n",
    "            cell.set_width(0.07)  # match body cell width\n",
    "            cell.set_height(cell.get_height())\n",
    "            cell.get_text().set_fontsize(6)\n",
    "\n",
    "        else:\n",
    "            val = df.iloc[row - 1, col]\n",
    "\n",
    "            if col_name == 'region':\n",
    "                cell.set_facecolor(beryl_palette.get(val, '#ffffff'))\n",
    "                cell.get_text().set_fontsize(10)\n",
    "                cell.get_text().set_weight('bold')\n",
    "                cell.set_width(0.18)\n",
    "\n",
    "            # elif col_name == 'cosmos':\n",
    "            #     cell.set_facecolor('#ffffff')\n",
    "            #     cell.get_text().set_fontsize(1)  # hide text\n",
    "            #     cell.set_width(0.15)\n",
    "\n",
    "            elif isinstance(val, (float, int)):\n",
    "                cell.set_width(0.12)\n",
    "                if 'sc' in col_name:\n",
    "                    if np.isnan(val):\n",
    "                        cell.set_facecolor('#f2f2f2')\n",
    "                    else:\n",
    "                        rgb = colormap_lookup.get(col_name, lambda x: (1, 1, 1))(val)\n",
    "                        cell.set_facecolor(to_hex(rgb))\n",
    "                else:\n",
    "                    if val == 0:\n",
    "                        cell.set_facecolor('#f2f2f2')\n",
    "                    elif np.isnan(val):\n",
    "                        cell.set_facecolor('#f2f2f2')\n",
    "                    else:\n",
    "                        # rgb = cmap(val)\n",
    "                        rgb = colormap_lookup.get(col_name, lambda x: (1, 1, 1))(val)\n",
    "                        cell.set_facecolor(to_hex(rgb))\n",
    "                cell.get_text().set_text('')  # completely remove number\n",
    "            else:\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.get_text().set_fontsize(6)\n",
    "\n",
    "            cell.set_height(cell.get_height())\n",
    "            cell.set_linewidth(0.5)\n",
    "            cell.set_edgecolor('white')\n",
    "\n",
    "    plt.savefig(out_path, bbox_inches='tight', dpi=350, transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_table(times, alpha=0.05, ptype='p_euc_c', datatype='true_block'):\n",
    "    table = {}\n",
    "    for timeframe in times:\n",
    "        splits = run_align[timeframe]\n",
    "        if len(splits) == 1:\n",
    "            split_name = splits[0]\n",
    "        else:\n",
    "            split_name = 'combined_'+\"_\".join(splits)\n",
    "        res = manifold_to_csv(split_name, alpha, ptype)\n",
    "        min_val = res['amp_euc'].min()\n",
    "        max_val = res['amp_euc'].max()\n",
    "        res['amp_euc'] = (res['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "        res['amp_euc'] *= res['significant']\n",
    "        res = res.fillna(0)\n",
    "        table[timeframe] = res['amp_euc']\n",
    "        \n",
    "    table = pd.DataFrame(data=table)\n",
    "    table['region'] = res.region\n",
    "    table['beryl_hex'] = res.region.apply(swanson_to_beryl_hex, args=[br])\n",
    "    beryl_palette = dict(zip(table['region'], table['beryl_hex']))\n",
    "    table['sum'] = table[times].sum(axis=1)\n",
    "    table['cosmos'] = table['region'].apply(lambda r: beryl_to_cosmos(r, br))\n",
    "\n",
    "    # Load or compute region order\n",
    "    ordering_path = Path(meta_pth, 'region_order.txt')\n",
    "    if ordering_path.exists():\n",
    "        with open(ordering_path) as f:\n",
    "            region_order = [line.strip() for line in f]\n",
    "    else:\n",
    "        table = table.sort_values(['cosmos', 'sum'], ascending=[True, False])\n",
    "        region_order = table['region'].tolist()\n",
    "        with open(ordering_path, 'w') as f:\n",
    "            f.writelines(r + '\\n' for r in region_order)\n",
    "\n",
    "    table['region'] = pd.Categorical(table['region'], categories=region_order, ordered=True)\n",
    "    table = table.sort_values('region')\n",
    "\n",
    "    # Drop non-display columns\n",
    "    df_to_plot = table.drop(columns=['beryl_hex', 'sum', 'cosmos']).reset_index(drop=True)\n",
    "    cols = df_to_plot.columns.tolist()\n",
    "    cols = ['region'] + [c for c in cols if c != 'region']\n",
    "    df_to_plot = df_to_plot[cols]\n",
    "\n",
    "    colormap_lookup = {timeframe: get_cmap_(timeframe) for timeframe in times}\n",
    "    plot_table_with_styles(\n",
    "        df=df_to_plot,\n",
    "        colormap_lookup=colormap_lookup,\n",
    "        beryl_palette=beryl_palette,\n",
    "        out_path=Path(meta_pth, f'table_{datatype}_alltimes_{ptype}_{alpha}.png')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "46b1b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.05\n",
    "ptype = 'p_mean_c'\n",
    "\n",
    "datatype = 'true_block'\n",
    "times = ['block_duringchoice', 'block_duringstim', 'intertrial0']\n",
    "# datatype = 'act_block'\n",
    "# times = ['act_block_duringchoice', 'act_block_duringstim', 'act_intertrial0']\n",
    "\n",
    "for alpha in [0.01, 0.05]:\n",
    "    table = plot_table(times, ptype=ptype, alpha=alpha, datatype=datatype)\n",
    "\n",
    "# times = ['stim_duringstim0', 'choice_duringstim0', 'stim_duringchoice0', 'choice_duringchoice0']\n",
    "# table = plot_table_combined(times, ptype=ptype, datatype='stimchoice0', alpha=alpha)\n",
    "\n",
    "# times = ['stim_duringstim', 'choice_duringstim', 'stim_duringchoice', 'choice_duringchoice']\n",
    "# table = plot_table_combined(times, ptype=ptype, datatype='stimchoice', alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0382fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = ['stim_duringstim0', 'choice_duringstim0', 'stim_duringchoice0', 'choice_duringchoice0']\n",
    "# times = ['stim_duringstim', 'choice_duringstim', 'stim_duringchoice', 'choice_duringchoice']\n",
    "times = ['stim_duringstim0', 'choice_duringstim0', 'stim_duringchoice0', 'choice_duringchoice0']\n",
    "ptype = 'p_mean_c'\n",
    "metric = 'int_mov'\n",
    "# metric = 'move_shape'\n",
    "sc_threshold = 0.6\n",
    "\n",
    "plot_sc_table(times, ptype, alpha=0.05, metric=metric, sc_threshold=sc_threshold)\n",
    "\n",
    "# for time in times:\n",
    "#     res = manifold_to_csv(time, 0.05, ptype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sc_table(times, ptype, alpha=0.05, n=20, combined_p=True, slope_threshold=0.05, \n",
    "                 sc_threshold=0.6, amp_loc_threshold=69):\n",
    "    \n",
    "    # # Plot comparison table\n",
    "    sc_splits = {'sc_duringchoice': [time for time in times if 'duringchoice' in time and time.startswith('stim')] + \n",
    "                                  [time for time in times if 'duringchoice' in time and time.startswith('choice')],\n",
    "                 'sc_duringstim': [time for time in times if 'duringstim' in time and time.startswith('stim')] + \n",
    "                                  [time for time in times if 'duringstim' in time and time.startswith('choice')]}\n",
    "\n",
    "    tables, res = {}, {}\n",
    "\n",
    "    if combined_p:\n",
    "        for time in times:\n",
    "            splits = run_align[time]\n",
    "            split_name = 'combined_'+\"_\".join(splits)\n",
    "\n",
    "            compute_amp_slope(time, n)\n",
    "            results = manifold_to_csv(split_name, alpha, ptype)\n",
    "            # min_val = results['amp_euc'].min()\n",
    "            # max_val = results['amp_euc'].max()\n",
    "            # results['amp_euc'] = (results['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "\n",
    "            results['amp_euc'] *= results['significant']\n",
    "            results = results.fillna(0)\n",
    "            tables[time] = results['amp_euc']\n",
    "            tables[f'{time}_amp_slope'] = results['amp_slope']\n",
    "            tables[f'{time}_slope_last'] = results['slope_last']\n",
    "            tables[f'{time}_amp_loc'] = results['amp_loc']\n",
    "            tables[f'{time}_slope_last_5'] = results['slope_last_5']\n",
    "\n",
    "        # add in short splits for stim\n",
    "        time = 'stim_duringstim1'\n",
    "        splits = run_align[time]\n",
    "        split_name = 'combined_'+\"_\".join(splits)\n",
    "        results = manifold_to_csv(split_name, alpha, ptype)\n",
    "        tables[time] = results['significant']\n",
    "\n",
    "    else:\n",
    "        for time in times:\n",
    "            splits = run_align[time]\n",
    "            for split in splits:\n",
    "                results = manifold_to_csv(split, alpha, ptype)\n",
    "                results['amp_euc'] *= results['significant']\n",
    "                # min_val = results['amp_euc'].min()\n",
    "                # max_val = results['amp_euc'].max()\n",
    "                # results['amp_euc'] = (results['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "                results = results.fillna(0)\n",
    "                if time not in tables:\n",
    "                    tables[time] = results['amp_euc']\n",
    "                else:   \n",
    "                    tables[time] += results['amp_euc']\n",
    "        \n",
    "    tables['region'] = results['region']\n",
    "\n",
    "    # identify regions with move_init ramp shape based on choice diff curve shape, movement aligned\n",
    "    meta_split = 'sc_duringchoice'\n",
    "    splits = sc_splits[meta_split]\n",
    "    res[f'{meta_split}_amp_loc'] = tables[f'{splits[1]}_amp_loc'] > amp_loc_threshold\n",
    "    res[f'{meta_split}_slope_last'] = tables[f'{splits[1]}_slope_last'] > slope_threshold\n",
    "    res[f'{meta_split}_slope_last_5'] = tables[f'{splits[1]}_slope_last_5'] > 0\n",
    "\n",
    "    # res[f'{meta_split}_move_shape'] = np.full(len(res[f'{meta_split}_amp_loc']), np.nan)  # Initialize with NaN\n",
    "    move_shape = (res[f'{meta_split}_slope_last']\n",
    "                    & res[f'{meta_split}_slope_last_5']\n",
    "                    & res[f'{meta_split}_amp_loc'])\n",
    "    # res[f'{meta_split}_move_shape'][move_shape] = 1\n",
    "\n",
    "    for meta_split in sc_splits:                \n",
    "        # Calculate choice-stim metric, within [0,1] to be plotted\n",
    "        splits = sc_splits[meta_split]\n",
    "        res[meta_split] = tables[splits[1]]/(tables[splits[0]] + tables[splits[1]])\n",
    "\n",
    "        res[f'{meta_split}_move_init'] = (move_shape & res['sc_duringchoice'] > sc_threshold).astype(int)\n",
    "        \n",
    "        res[f'{meta_split}_integrator'] = ((res[meta_split] > 0 \n",
    "                                            & res['sc_duringchoice_slope_last']).astype(int) - res[f'{meta_split}_move_init'])\n",
    "        # res[f'{meta_split}_integrator'] = (res[meta_split] > 0 & res['sc_duringchoice_slope_last']).astype(int)\n",
    "        \n",
    "        res[f'{meta_split}_int_mov'] = np.full(len(res[meta_split]), np.nan)  # Initialize with NaN\n",
    "        res[f'{meta_split}_int_mov'][res[f'{meta_split}_move_init'] == 1] = 1\n",
    "        res[f'{meta_split}_int_mov'][res[f'{meta_split}_integrator'] == 1] = 0.5\n",
    "        # res[f'{meta_split}_int_mov'][res[meta_split] == 0] = 0\n",
    "\n",
    "    # add in short splits results for stim\n",
    "    mask = np.isnan(res['sc_duringstim']) & (tables['stim_duringstim1'] == 1)\n",
    "    res['sc_duringstim'][mask] = 0\n",
    "    res['sc_duringstim_int_mov'][res['sc_duringstim']==0] = 0\n",
    "    \n",
    "    res['region'] = results['region']\n",
    "    res = pd.DataFrame(data=res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f544e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_table_summary(sc_times, timing_splits, ptype='p_mean_c', alpha=0.05, combined_p=True, \n",
    "                                sc_threshold=0.6, slope_threshold=0.05, amp_loc_threshold=69):\n",
    "    sc_splits = ['sc_duringchoice_int_mov', 'sc_duringstim_int_mov']\n",
    "\n",
    "    # Handle SC splits with combined L/R\n",
    "    table = get_sc_table(sc_times, ptype, alpha=alpha, combined_p=combined_p,\n",
    "                         sc_threshold=sc_threshold, slope_threshold=slope_threshold, \n",
    "                         amp_loc_threshold=amp_loc_threshold)\n",
    "\n",
    "    # Handle timing splits\n",
    "    for timing_split in timing_splits:\n",
    "        if combined_p:\n",
    "            splits = run_align[timing_split]\n",
    "            split_name = 'combined_'+\"_\".join(splits)\n",
    "            res = manifold_to_csv(split_name, alpha, ptype)\n",
    "            min_val = res['amp_euc'].min()\n",
    "            max_val = res['amp_euc'].max()\n",
    "            res['amp_euc'] = (res['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "            res['amp_euc'] *= res['significant']\n",
    "            res = res.fillna(0)\n",
    "            table[timing_split] = res['amp_euc']\n",
    "        else:\n",
    "            for split in run_align[timing_split]:\n",
    "                res = manifold_to_csv(split, alpha, ptype)\n",
    "                min_val = res['amp_euc'].min()\n",
    "                max_val = res['amp_euc'].max()\n",
    "                res['amp_euc'] = (res['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "                res['amp_euc'] *= res['significant']\n",
    "                res = res.fillna(0)\n",
    "                if timing_split not in table:\n",
    "                    table[timing_split] = res['amp_euc']\n",
    "                else:\n",
    "                    table[timing_split] += res['amp_euc']\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(table)\n",
    "    df['beryl_hex'] = df['region'].apply(swanson_to_beryl_hex, args=[br])\n",
    "    beryl_palette = dict(zip(df['region'], df['beryl_hex']))\n",
    "    df['cosmos'] = df['region'].apply(lambda r: beryl_to_cosmos(r, br))\n",
    "    df['sum'] = df[sc_splits + timing_splits].sum(axis=1, skipna=True)\n",
    "\n",
    "    # Region ordering\n",
    "    ordering_path = Path(meta_pth, 'region_order.txt')\n",
    "    if ordering_path.exists():\n",
    "        with open(ordering_path) as f:\n",
    "            region_order = [line.strip() for line in f]\n",
    "    else:\n",
    "        df_sorted = df.sort_values(['cosmos', 'sum'], ascending=[True, False])\n",
    "        region_order = df_sorted['region'].tolist()\n",
    "        with open(ordering_path, 'w') as f:\n",
    "            f.writelines(r + '\\n' for r in region_order)\n",
    "\n",
    "    df['region'] = pd.Categorical(df['region'], categories=region_order, ordered=True)\n",
    "    df = df.sort_values('region')\n",
    "    column_names = df.columns.difference(['region']).tolist()\n",
    "\n",
    "    # Prepare and plot\n",
    "    choice_time = [time for time in timing_splits if 'duringchoice' in time]\n",
    "    stim_time = [time for time in timing_splits if 'duringstim' in time]\n",
    "    display_cols = ['region'] + ['sc_duringchoice_int_mov'] + choice_time + ['sc_duringstim_int_mov'] + stim_time\n",
    "    df_to_plot = df[display_cols].reset_index(drop=True)\n",
    "\n",
    "    colormap_lookup = {name: get_cmap_(name) for name in column_names}\n",
    "\n",
    "    if 'act' in timing_splits[0]:\n",
    "        block_type = 'act_block'\n",
    "    else:\n",
    "        block_type = 'true_block'\n",
    "\n",
    "    if 'stim_duringstim0' in sc_times:\n",
    "        out_path = Path(meta_pth, f'table_{block_type}_combined_summary0_{ptype}_combinedp{combined_p}_{alpha}.png')\n",
    "    elif 'stim_duringstim1' in sc_times:\n",
    "        out_path = Path(meta_pth, f'table_{block_type}_combined_summary1_{ptype}_combinedp{combined_p}_{alpha}.png')\n",
    "    else: \n",
    "        out_path = Path(meta_pth, f'table_{block_type}_combined_summary_{ptype}_combinedp{combined_p}_{alpha}.png')\n",
    "    plot_table_with_styles(\n",
    "        df=df_to_plot,\n",
    "        beryl_palette=beryl_palette,\n",
    "        colormap_lookup=colormap_lookup,\n",
    "        out_path=out_path\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42aed94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sc_table(times, ptype, metric='int_mov', alpha=0.05, slope_threshold=0.05, \n",
    "                 sc_threshold=0.7, amp_loc_threshold=69):\n",
    "    '''\n",
    "    metric: 'int_mov' (region category: integrator, movement, stim) or 'move_shape' or 'sc'\n",
    "    '''\n",
    "\n",
    "    if metric == 'int_mov': \n",
    "        sc_splits = ['sc_duringchoice_int_mov', 'sc_duringstim_int_mov']\n",
    "    elif metric == 'move_shape':\n",
    "        sc_splits = ['sc_duringchoice_move_shape']\n",
    "    elif metric == 'sc':\n",
    "        sc_splits = ['sc_duringchoice', 'sc_duringstim']\n",
    "    else: \n",
    "        raise ValueError(f\"Invalid metric: {metric}\")\n",
    "    \n",
    "    if 'choice_duringstim0' in times:\n",
    "        datatype = 'stimchoice0'\n",
    "    else:\n",
    "        datatype = 'stimchoice'\n",
    "    datatype = f'{datatype}_{metric}'\n",
    "\n",
    "    res = get_sc_table(times, ptype, alpha, sc_threshold=sc_threshold, \n",
    "                       slope_threshold=slope_threshold, amp_loc_threshold=amp_loc_threshold)\n",
    "    \n",
    "    # Add hex values for Beryl regions\n",
    "    res['beryl_hex'] = res.region.apply(swanson_to_beryl_hex,args=[br])    \n",
    "    beryl_palette = dict(zip(res.region, res.beryl_hex))\n",
    "        \n",
    "    # Order columns according to panels in Figure\n",
    "    names = ['region'] #, 'region_color']\n",
    "    for split in sc_splits:\n",
    "        names.append(split)\n",
    "    res = res[names]\n",
    "\n",
    "    # Sum values in each row to use for sorting\n",
    "    res['sum']  = res[names[2:]].apply(np.sum,axis=1)\n",
    "    res['cosmos'] = res['region'].apply(lambda r: beryl_to_cosmos(r, br))\n",
    "    \n",
    "    # Load or compute region order\n",
    "    ordering_path = Path(meta_pth, 'region_order.txt')\n",
    "    if ordering_path.exists():\n",
    "        with open(ordering_path) as f:\n",
    "            region_order = [line.strip() for line in f]\n",
    "    else:\n",
    "        res = res.sort_values(['cosmos', 'sum'], ascending=[True, False])\n",
    "        region_order = res['region'].tolist()\n",
    "        with open(ordering_path, 'w') as f:\n",
    "            f.writelines(r + '\\n' for r in region_order)\n",
    "\n",
    "    res['region'] = pd.Categorical(res['region'], categories=region_order, ordered=True)\n",
    "    res = res.sort_values('region')\n",
    "    \n",
    "    df_to_plot = res.drop(columns=['cosmos', 'sum']).reset_index(drop=True)\n",
    "\n",
    "    # Ensure region is first column\n",
    "    cols = df_to_plot.columns.tolist()\n",
    "    cols = ['region'] + [c for c in cols if c != 'region']\n",
    "    df_to_plot = df_to_plot[cols]\n",
    "\n",
    "    # Build column-specific colormap dictionary\n",
    "    colormap_lookup = {col: get_cmap_(col) for col in df_to_plot.columns if col != 'region'}\n",
    "\n",
    "    # Export using correct filename\n",
    "    outname = f'table_{datatype}_{ptype}.png'\n",
    "    plot_table_with_styles(\n",
    "        df=df_to_plot,\n",
    "        beryl_palette=beryl_palette,\n",
    "        colormap_lookup=colormap_lookup,\n",
    "        out_path=Path(meta_pth, outname)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a786407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# old version\n",
    "sigl=0.05\n",
    "# meta_split = 'intertrial_1.0' #'sc_duringstim1' 'intertrial_block_only' 'act_intertrial'\n",
    "fdr = 'p_euc_c1' #'p_euc_c1' or 'p_euc' or 'p_euc_c'\n",
    "\n",
    "for meta_split in expanded_meta_splits:\n",
    "# for meta_split in ['intertrial_1.0']:\n",
    "    # fdr correction on raw data, for fdr = 'p_euc_c1' correction over splits, and 'p_euc_c' correction over regions\n",
    "    fdr_splits(meta_split, sigl)\n",
    "    fdr_reg(meta_split, sigl)\n",
    "    \n",
    "    # load data to csv files\n",
    "    manifold_to_csv(meta_split, sigl, fdr)\n",
    "    \n",
    "    res = plot_table(meta_split, 'amp', fdr)\n",
    "    res.to_html(Path(meta_pth,f'table_{meta_split}.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf945927",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_combined_sc_table_summary(sc_times, ptype='p_euc_c1', alpha=0.05, combined_p=True):\n",
    "    timing_splits = ['block_duringchoice', 'block_duringstim']\n",
    "    sc_splits = ['sc_duringchoice', 'sc_duringstim']\n",
    "    # region_sets = []\n",
    "    # region_map = {}\n",
    "\n",
    "    # Handle SC splits with combined L/R\n",
    "    table = get_sc_table(sc_times, ptype, alpha=alpha, combined_p=combined_p)\n",
    "    # tables = {}\n",
    "    # for meta_split in sc_splits:\n",
    "    #     r = load_meta_results(f'{meta_split}1')\n",
    "    #     splits = meta_splits[f'{meta_split}1']\n",
    "    #     newsplits = meta_splits[f'{meta_split}']\n",
    "    #     r = r.fillna(0)\n",
    "\n",
    "    #     # Combine L/R\n",
    "    #     r[f'amp_{newsplits[0]}'] = (\n",
    "    #         r[f'amp_{splits[0]}'] * r[f'{splits[0]}_significant'] +\n",
    "    #         r[f'amp_{splits[1]}'] * r[f'{splits[1]}_significant']\n",
    "    #     ) / 2\n",
    "    #     r[f'amp_{newsplits[1]}'] = (\n",
    "    #         r[f'amp_{splits[2]}'] * r[f'{splits[2]}_significant'] +\n",
    "    #         r[f'amp_{splits[3]}'] * r[f'{splits[3]}_significant']\n",
    "    #     ) / 2\n",
    "\n",
    "    #     tables[meta_split] = r\n",
    "    #     splits = meta_splits[meta_split]\n",
    "    #     amp0 = f'amp_{splits[0]}'\n",
    "    #     amp1 = f'amp_{splits[1]}'\n",
    "    #     choice_stim = r[amp1] / (r[amp0] + r[amp1])\n",
    "    #     # region_map[meta_split] = r['region']        \n",
    "    #     table[meta_split] = choice_stim\n",
    "    #     # region_sets.append(r['region'])\n",
    "\n",
    "    # Handle timing splits\n",
    "    for timing_split in timing_splits:\n",
    "        if combined_p:\n",
    "            splits = run_align[timing_split]\n",
    "            split_name = 'combined_'+\"_\".join(splits)\n",
    "            res = manifold_to_csv(split_name, alpha, ptype)\n",
    "            min_val = res['amp_euc'].min()\n",
    "            max_val = res['amp_euc'].max()\n",
    "            res['amp_euc'] = (res['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "            res['amp_euc'] *= res['significant']\n",
    "            res = res.fillna(0)\n",
    "            # region_map[timing_split] = res['region']\n",
    "            table[timing_split] = res['amp_euc']\n",
    "            # region_sets.append(res['region'])\n",
    "        else:\n",
    "            for split in run_align[timing_split]:\n",
    "                res = manifold_to_csv(split, alpha, ptype)\n",
    "                min_val = res['amp_euc'].min()\n",
    "                max_val = res['amp_euc'].max()\n",
    "                res['amp_euc'] = (res['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "                res['amp_euc'] *= res['significant']\n",
    "                res = res.fillna(0)\n",
    "                if timing_split not in table:\n",
    "                    table[timing_split] = res['amp_euc']\n",
    "                else:\n",
    "                    table[timing_split] += res['amp_euc']\n",
    "\n",
    "    # # Union of all regions\n",
    "    # all_regions = pd.Index(sorted(set().union(*region_sets)))\n",
    "\n",
    "    # # Align each column to full region list, filling with NaN\n",
    "    # for k in table:\n",
    "    #     col = table[k]\n",
    "    #     col = pd.Series(col.values, index=region_map[k])\n",
    "    #     table[k] = col.reindex(all_regions)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(table)\n",
    "    # df['region'] = all_regions\n",
    "    df['beryl_hex'] = df['region'].apply(swanson_to_beryl_hex, args=[br])\n",
    "    beryl_palette = dict(zip(df['region'], df['beryl_hex']))\n",
    "    df['cosmos'] = df['region'].apply(lambda r: beryl_to_cosmos(r, br))\n",
    "    df['sum'] = df[sc_splits + timing_splits].sum(axis=1, skipna=True)\n",
    "\n",
    "    # Region ordering\n",
    "    ordering_path = Path(meta_pth, 'region_order.txt')\n",
    "    if ordering_path.exists():\n",
    "        with open(ordering_path) as f:\n",
    "            region_order = [line.strip() for line in f]\n",
    "    else:\n",
    "        df_sorted = df.sort_values(['cosmos', 'sum'], ascending=[True, False])\n",
    "        region_order = df_sorted['region'].tolist()\n",
    "        with open(ordering_path, 'w') as f:\n",
    "            f.writelines(r + '\\n' for r in region_order)\n",
    "\n",
    "    df['region'] = pd.Categorical(df['region'], categories=region_order, ordered=True)\n",
    "    df = df.sort_values('region')\n",
    "    column_names = df.columns.difference(['region']).tolist()\n",
    "\n",
    "    # Prepare and plot\n",
    "    display_cols = ['region'] + ['sc_duringchoice', 'block_duringchoice',\n",
    "                                 'sc_duringstim', 'block_duringstim']\n",
    "    df_to_plot = df[display_cols].reset_index(drop=True)\n",
    "\n",
    "    colormap_lookup = {name: get_cmap_(name) for name in column_names}\n",
    "\n",
    "    if 'stim_duringstim0' in sc_times:\n",
    "        out_path = Path(meta_pth, f'table_combined_sc_summary0_{ptype}_combinedp{combined_p}.png')\n",
    "    else: \n",
    "        out_path = Path(meta_pth, f'table_combined_sc_summary_{ptype}_combinedp{combined_p}.png')\n",
    "    plot_table_with_styles(\n",
    "        df=df_to_plot,\n",
    "        beryl_palette=beryl_palette,\n",
    "        colormap_lookup=colormap_lookup,\n",
    "        out_path=out_path\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "86b03cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# times = ['stim_duringstim', 'choice_duringstim', 'stim_duringchoice', 'choice_duringchoice']\n",
    "times = ['stim_duringchoice0', 'choice_duringchoice0', 'stim_duringstim0', 'choice_duringstim0']\n",
    "\n",
    "timing_splits = ['act_block_duringchoice', 'act_block_duringstim']\n",
    "# timing_splits = ['block_duringchoice', 'block_duringstim']\n",
    "\n",
    "# sigl=0.05\n",
    "ptype = 'p_mean_c'\n",
    "combined_p=True\n",
    "sc_threshold=0.6\n",
    "\n",
    "for sigl in [0.05, 0.01]:\n",
    "    plot_combined_table_summary(times, timing_splits, ptype=ptype, alpha=sigl, \n",
    "                                combined_p=combined_p, sc_threshold=sc_threshold)\n",
    "# plot_combined_sc_table_summary(times, ptype=ptype, alpha=sigl, combined_p=combined_p)\n",
    "\n",
    "# for ptype in ['p_mean_c', 'p_amp_c', 'p_max_c']:\n",
    "    # plot_combined_table_summary(times, ptype=ptype, alpha=sigl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c62e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sigl = 0.05\n",
    "ptype = 'p_euc_c1' #'p_euc_c1' 'p_euc'\n",
    "times = ['duringstim','act_duringstim','duringchoice',\n",
    "         'act_duringchoice','intertrial','act_intertrial']\n",
    "blocktype = 'all' #'true' 'act' 'all'\n",
    "\n",
    "for meta_split in times:\n",
    "    if ptype == 'p_euc_c1':\n",
    "        plot_tables.fdr_splits(meta_split, sigl)\n",
    "    elif ptype == 'p_euc_c':\n",
    "        plot_tables.fdr_reg(meta_split, sigl)\n",
    "\n",
    "    manifold_to_csv(meta_split,sigl,ptype)\n",
    "    \n",
    "plot_block_alltimes(times, ptype, blocktype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ae744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_onetype(sc_times, sc_type, timing_split, ptype='p_euc', alpha=0.05, combined_p=True,\n",
    "                          sc_threshold=0.6, slope_threshold=0.05, amp_loc_threshold=69):\n",
    "\n",
    "    '''\n",
    "    sc_type: 'stim' or 'choice' or 'integrator'\n",
    "    timing_split: 'block_duringstim' or 'block_duringchoice' or 'act_block_duringstim' or 'act_block_duringchoice'\n",
    "    '''\n",
    "\n",
    "    table = {}\n",
    "    # region_sets = []\n",
    "    # region_map = {}\n",
    "\n",
    "    sc_split = 'sc_duringchoice_int_mov' if 'choice' in timing_split else 'sc_duringstim_int_mov'\n",
    "    print(sc_split, timing_split)\n",
    "\n",
    "    # Handle SC splits with combined L/R\n",
    "    res = get_sc_table(sc_times, ptype, alpha=alpha, combined_p=combined_p, \n",
    "                       sc_threshold=sc_threshold, slope_threshold=slope_threshold, \n",
    "                       amp_loc_threshold=amp_loc_threshold)\n",
    "    table[sc_split] = res[sc_split]\n",
    "    table['region'] = res['region']\n",
    "\n",
    "    # Handle timing split\n",
    "    if combined_p:\n",
    "        splits = run_align[timing_split]\n",
    "        combined_name = 'combined_'+\"_\".join(splits)\n",
    "        res = manifold_to_csv(combined_name, alpha, ptype)\n",
    "        min_val = res['amp_euc'].min()\n",
    "        max_val = res['amp_euc'].max()\n",
    "        res['amp_euc'] = (res['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "        res['amp_euc'] *= res['significant']\n",
    "        res = res.fillna(0)\n",
    "        table[timing_split] = res['amp_euc']\n",
    "    else:\n",
    "        for split in run_align[timing_split]:\n",
    "            res = manifold_to_csv(split, alpha, ptype)\n",
    "            min_val = res['amp_euc'].min()\n",
    "            max_val = res['amp_euc'].max()\n",
    "            res['amp_euc'] = (res['amp_euc'] - min_val) / (max_val - min_val) + 1e-4\n",
    "            res['amp_euc'] *= res['significant']\n",
    "            res = res.fillna(0)\n",
    "            if timing_split not in table:\n",
    "                table[timing_split] = res['amp_euc']\n",
    "            else:\n",
    "                table[timing_split] += res['amp_euc']\n",
    "\n",
    "    # Binarize and combine timing split to sc_split\n",
    "    table[timing_split] = table[timing_split].apply(lambda x: 1 if x > 0 else np.nan)\n",
    "    if sc_type == 'stim':\n",
    "        table[sc_split] = table[sc_split].apply(lambda x: 1 if x == 0 else np.nan)\n",
    "        table['combined'] = table[sc_split] * table[timing_split]\n",
    "    elif sc_type == 'choice':\n",
    "        table[sc_split] = table[sc_split].apply(lambda x: 1 if x == 1 else np.nan)\n",
    "        table['combined'] = table[sc_split] * table[timing_split]\n",
    "    elif sc_type == 'integrator':\n",
    "        table[sc_split] = table[sc_split].apply(lambda x: 1 if 0<x<1 else np.nan)\n",
    "        table['combined'] = table[sc_split] * table[timing_split]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid sc_type: {sc_type}\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(table)\n",
    "    # df['region'] = all_regions\n",
    "    df['beryl_hex'] = df['region'].apply(swanson_to_beryl_hex, args=[br])\n",
    "    beryl_palette = dict(zip(df['region'], df['beryl_hex']))\n",
    "\n",
    "    # Region ordering\n",
    "    ordering_path = Path(meta_pth, 'region_order.txt')\n",
    "    with open(ordering_path) as f:\n",
    "        region_order = [line.strip() for line in f]\n",
    "\n",
    "    df['region'] = pd.Categorical(df['region'], categories=region_order, ordered=True)\n",
    "    df = df.sort_values('region')\n",
    "\n",
    "    # Prepare and plot\n",
    "    display_cols = ['region'] + ['combined']\n",
    "    df_to_plot = df[display_cols].reset_index(drop=True)\n",
    "\n",
    "    colormap_lookup = {\n",
    "        'combined': get_cmap_('intertrial')\n",
    "    }\n",
    "    \n",
    "    regions_with_1 = df_to_plot.loc[df_to_plot['combined'] == 1, 'region'].tolist()\n",
    "\n",
    "    out_path = Path(meta_pth, f'table_combined_{sc_type}_{timing_split}_{ptype}_combinedp{combined_p}_{alpha}.png')\n",
    "    plot_table_with_styles(\n",
    "        df=df_to_plot,\n",
    "        beryl_palette=beryl_palette,\n",
    "        colormap_lookup=colormap_lookup,\n",
    "        out_path=out_path\n",
    "    )\n",
    "\n",
    "    return regions_with_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = ['stim_duringstim0', 'choice_duringstim0', 'stim_duringchoice0', 'choice_duringchoice0']\n",
    "# times = ['stim_duringstim', 'choice_duringstim', 'stim_duringchoice', 'choice_duringchoice']\n",
    "times = ['stim_duringstim0', 'choice_duringstim0', 'stim_duringchoice0', 'choice_duringchoice0']\n",
    "\n",
    "ptype = 'p_mean_c'\n",
    "combined_p = True\n",
    "sc_threshold = 0.6\n",
    "alpha = 0.05\n",
    "\n",
    "stim_regs = plot_combined_onetype(times, 'stim', 'act_block_duringstim', ptype, combined_p=combined_p, \n",
    "                      sc_threshold=sc_threshold, alpha=alpha)\n",
    "move_regs_choice = plot_combined_onetype(times, 'choice', 'act_block_duringchoice', ptype, combined_p=combined_p, \n",
    "                      sc_threshold=sc_threshold, alpha=alpha)\n",
    "int_regs_stim = plot_combined_onetype(times, 'integrator', 'act_block_duringstim', ptype, combined_p=combined_p, \n",
    "                      sc_threshold=sc_threshold, alpha=alpha)\n",
    "int_regs_choice = plot_combined_onetype(times, 'integrator', 'act_block_duringchoice', ptype, combined_p=combined_p, \n",
    "                      sc_threshold=sc_threshold, alpha=alpha)\n",
    "move_regs_stim = plot_combined_onetype(times, 'choice', 'act_block_duringstim', ptype, combined_p=combined_p, \n",
    "                      sc_threshold=sc_threshold, alpha=alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e444e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
